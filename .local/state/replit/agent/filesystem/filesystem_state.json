{"file_contents":{"build_simple.sh":{"content":"#!/bin/bash\n\n# Build script for macOS AutoTune Plugin\n# This script builds VST3 and AU formats for macOS\n\necho \"🎵 Building ProAutoTune Plugin...\"\n\n# Create build directory\nmkdir -p build\ncd build\n\n# Configure with CMake\necho \"📦 Configuring build system...\"\ncmake .. -DCMAKE_BUILD_TYPE=Release \\\n         -DCMAKE_OSX_ARCHITECTURES=\"arm64;x86_64\" \\\n         -DCMAKE_OSX_DEPLOYMENT_TARGET=10.15\n\n# Check if configuration was successful\nif [ $? -ne 0 ]; then\n    echo \"❌ CMake configuration failed!\"\n    exit 1\nfi\n\n# Build the plugin\necho \"🔨 Building plugin...\"\ncmake --build . --config Release --parallel $(sysctl -n hw.ncpu)\n\n# Check if build was successful\nif [ $? -ne 0 ]; then\n    echo \"❌ Build failed!\"\n    exit 1\nfi\n\necho \"✅ Build completed successfully!\"\necho \"\"\necho \"📍 Plugin locations:\"\necho \"   VST3: ~/Library/Audio/Plug-Ins/VST3/ProAutoTune.vst3\"\necho \"   AU:   ~/Library/Audio/Plug-Ins/Components/ProAutoTune.component\"\necho \"\"\necho \"🎉 Ready to use in your DAW!\"\n","size_bytes":995},"install_dependencies.sh":{"content":"#!/bin/bash\n\n# Install dependencies for macOS\necho \"🔧 Installing macOS dependencies...\"\n\n# Check if Homebrew is installed\nif ! command -v brew &> /dev/null; then\n    echo \"❌ Homebrew not found. Please install Homebrew first:\"\n    echo \"   /bin/bash -c \\\"\\$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\\\"\"\n    exit 1\nfi\n\n# Install Rubber Band Library (optional but recommended)\necho \"📦 Installing Rubber Band Library...\"\nbrew install rubberband\n\n# Install CMake if not present\nif ! command -v cmake &> /dev/null; then\n    echo \"📦 Installing CMake...\"\n    brew install cmake\nfi\n\necho \"✅ Dependencies installed successfully!\"\necho \"\"\necho \"Now you can build the plugin:\"\necho \"   ./build_simple.sh\"","size_bytes":742},"replit.md":{"content":"# AutoTune Plugin\n\n## Overview\n\nThis is a professional audio plugin project that implements real-time pitch correction (AutoTune) functionality using JUCE framework. The plugin provides multiple pitch correction modes including Classic, Hard, and AI-powered correction using CREPE/DDSP models. It features a comprehensive GUI with parameter controls for speed, amount, key/scale selection, and mode switching. The project is designed to create VST3 and AU plugins for macOS with a professional interface similar to industry-standard pitch correction tools.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Core Framework Architecture\n- **JUCE Framework**: Primary audio plugin framework handling audio processing, GUI rendering, and plugin format compatibility\n- **CMake Build System**: Cross-platform build configuration with automatic dependency management\n- **C++17 Standard**: Modern C++ features for robust audio processing\n\n### Audio Processing Architecture\n- **PluginProcessor**: Main DSP pipeline controller managing audio buffer processing and parameter state\n- **PitchCorrectionEngine**: Core pitch correction algorithms implementing multiple correction modes\n- **Real-time Processing**: Low-latency audio processing optimized for live performance scenarios\n\n### User Interface Architecture\n- **Component-based GUI**: JUCE component hierarchy with custom look-and-feel styling\n- **PluginEditor**: Main interface controller managing all GUI components and parameter binding\n- **LookAndFeel**: Custom styling system for professional interface appearance\n- **ModeSelector**: Dynamic interface switching between different correction modes\n\n### Parameter Management\n- **Parameters Module**: Centralized parameter definitions and value mapping\n- **PresetManager**: User preset save/load functionality with persistent storage\n- **Real-time Parameter Updates**: Thread-safe parameter changes during audio processing\n\n### AI Integration Architecture\n- **AIModelLoader**: TensorFlow Lite/ONNX model loading and inference management\n- **CREPE Integration**: AI-powered pitch detection for enhanced accuracy\n- **DDSP Integration**: AI-based audio synthesis for natural-sounding corrections\n\n### Utility Systems\n- **Utils Module**: Frequency conversion utilities and mathematical operations\n- **Cross-platform Compatibility**: macOS-focused build with VST3/AU format support\n\n## External Dependencies\n\n### Audio Processing Libraries\n- **JUCE Framework 7.0.9**: Core audio plugin framework (automatically fetched via CMake)\n- **Rubber Band Library**: Professional pitch shifting and time stretching algorithms\n\n### AI/Machine Learning\n- **CREPE**: AI-powered pitch detection model for enhanced note recognition\n- **DDSP (Differentiable Digital Signal Processing)**: AI synthesis models for natural audio processing\n- **TensorFlow Lite or ONNX Runtime**: Machine learning inference engines for AI model execution\n\n### Build Dependencies\n- **CMake 3.15+**: Build system configuration and dependency management\n- **macOS SDK**: Platform-specific audio unit and VST3 plugin format support\n\n### Development Tools\n- **Xcode**: Primary development environment for macOS plugin development\n- **Terminal Build Scripts**: Automated build process via `./build_simple.sh` command\n\nThe architecture supports professional-grade real-time audio processing with multiple correction modes, AI-enhanced pitch detection, and a modern user interface designed to compete with industry-standard pitch correction tools like Antares Auto-Tune.","size_bytes":3575},"Source/AIModelLoader.cpp":{"content":"#include \"AIModelLoader.h\"\n#include \"Utils.h\"\n#include <algorithm>\n#include <cmath>\n#include <future>\n\n// PIMPL implementation to hide complex AI model details\nstruct AIModelLoader::Impl\n{\n    // Placeholder for actual AI model implementations\n    // In a real implementation, this would contain CREPE and DDSP model instances\n    \n    // Mock CREPE model\n    struct MockCrepeModel\n    {\n        bool loaded = false;\n        float sampleRate = 44100.0f;\n        \n        AIModelLoader::PitchPrediction predict(const std::vector<float>& audio)\n        {\n            AIModelLoader::PitchPrediction result;\n            \n            if (!loaded || audio.empty()) return result;\n            \n            // Mock pitch detection using autocorrelation (simplified)\n            const int minPeriod = static_cast<int>(sampleRate / 800.0f); // ~800Hz max\n            const int maxPeriod = static_cast<int>(sampleRate / 50.0f);   // ~50Hz min\n            \n            float maxCorrelation = 0.0f;\n            int bestPeriod = 0;\n            \n            for (int period = minPeriod; period < maxPeriod && period < audio.size() / 2; ++period)\n            {\n                float correlation = 0.0f;\n                int count = 0;\n                \n                for (int i = 0; i < static_cast<int>(audio.size()) - period; ++i)\n                {\n                    correlation += audio[i] * audio[i + period];\n                    count++;\n                }\n                \n                if (count > 0)\n                {\n                    correlation /= count;\n                    if (correlation > maxCorrelation)\n                    {\n                        maxCorrelation = correlation;\n                        bestPeriod = period;\n                    }\n                }\n            }\n            \n            if (bestPeriod > 0 && maxCorrelation > 0.3f)\n            {\n                result.frequency = sampleRate / bestPeriod;\n                result.confidence = juce::jmin(maxCorrelation * 2.0f, 1.0f);\n                result.voicing = result.confidence;\n                \n                // Mock harmonic analysis\n                result.harmonics.resize(8);\n                for (int i = 0; i < 8; ++i)\n                {\n                    result.harmonics[i] = result.confidence * std::pow(0.8f, i);\n                }\n            }\n            \n            return result;\n        }\n    } crepeModel;\n    \n    // Mock DDSP model\n    struct MockDDSPModel\n    {\n        bool loaded = false;\n        float sampleRate = 44100.0f;\n        \n        std::vector<float> synthesize(const AIModelLoader::SynthesisParams& params, int numSamples)\n        {\n            std::vector<float> output(numSamples, 0.0f);\n            \n            if (!loaded || params.fundamentalFreq <= 0.0f) return output;\n            \n            // Mock DDSP synthesis using additive synthesis\n            const float nyquist = sampleRate * 0.5f;\n            const int maxHarmonics = std::min(static_cast<int>(params.harmonicAmplitudes.size()), \n                                            static_cast<int>(nyquist / params.fundamentalFreq));\n            \n            for (int sample = 0; sample < numSamples; ++sample)\n            {\n                float sampleValue = 0.0f;\n                float time = static_cast<float>(sample) / sampleRate;\n                \n                // Add harmonics\n                for (int harmonic = 0; harmonic < maxHarmonics; ++harmonic)\n                {\n                    float freq = params.fundamentalFreq * (harmonic + 1);\n                    if (freq >= nyquist) break;\n                    \n                    float amplitude = harmonic < params.harmonicAmplitudes.size() ? \n                                    params.harmonicAmplitudes[harmonic] : 0.0f;\n                    \n                    sampleValue += amplitude * std::sin(2.0f * Utils::PI * freq * time);\n                }\n                \n                // Add noise component\n                if (!params.noiseLevel.empty())\n                {\n                    float noiseAmp = params.noiseLevel[sample % params.noiseLevel.size()];\n                    float noise = (static_cast<float>(rand()) / RAND_MAX - 0.5f) * 2.0f;\n                    sampleValue += noise * noiseAmp * 0.1f;\n                }\n                \n                // Apply loudness\n                sampleValue *= params.loudness;\n                \n                output[sample] = juce::jlimit(-1.0f, 1.0f, sampleValue);\n            }\n            \n            return output;\n        }\n    } ddspModel;\n    \n    // Performance monitoring\n    juce::Time lastProcessTime;\n    std::vector<float> processingTimes;\n    static constexpr int maxHistorySize = 100;\n};\n\nAIModelLoader::AIModelLoader()\n    : pImpl(std::make_unique<Impl>()),\n      currentQuality(ProcessingQuality::Standard),\n      useMultiThreading(true),\n      maxThreads(std::thread::hardware_concurrency()),\n      threadPool(maxThreads),\n      lastProcessingTime(0.0f),\n      averageProcessingTime(0.0f),\n      processedFrames(0)\n{\n    setupDefaultModelDirectory();\n    \n    // Initialize model info\n    crepeInfo.name = \"CREPE\";\n    crepeInfo.version = \"1.0.0 (Mock)\";\n    crepeInfo.description = \"Convolutional Representation for Pitch Estimation\";\n    crepeInfo.sampleRate = 44100.0f;\n    crepeInfo.inputSize = 1024;\n    crepeInfo.outputSize = 360; // CREPE outputs 360 pitch bins\n    \n    ddspInfo.name = \"DDSP\";\n    ddspInfo.version = \"1.0.0 (Mock)\";\n    ddspInfo.description = \"Differentiable Digital Signal Processing\";\n    ddspInfo.sampleRate = 44100.0f;\n    ddspInfo.inputSize = 1024;\n    ddspInfo.outputSize = 1024;\n}\n\nAIModelLoader::~AIModelLoader()\n{\n    unloadModels();\n}\n\nbool AIModelLoader::loadCrepeModel(const juce::File& modelFile)\n{\n    juce::ScopedLock lock(modelLock);\n    \n    if (!validateModelFile(modelFile, \"crepe\"))\n    {\n        lastError = AIError(AIError::ModelNotFound, \"CREPE model file not found or invalid\");\n        return false;\n    }\n    \n    try\n    {\n        // In a real implementation, this would load the actual CREPE model\n        // For now, we'll simulate loading\n        pImpl->crepeModel.loaded = true;\n        pImpl->crepeModel.sampleRate = 44100.0f;\n        \n        crepeInfo.isLoaded = true;\n        \n        if (onModelLoaded)\n            onModelLoaded(\"CREPE model loaded successfully\");\n            \n        return true;\n    }\n    catch (const std::exception& e)\n    {\n        lastError = AIError(AIError::ModelLoadFailed, \"Failed to load CREPE model: \" + juce::String(e.what()));\n        return false;\n    }\n}\n\nbool AIModelLoader::loadDDSPModel(const juce::File& modelFile)\n{\n    juce::ScopedLock lock(modelLock);\n    \n    if (!validateModelFile(modelFile, \"ddsp\"))\n    {\n        lastError = AIError(AIError::ModelNotFound, \"DDSP model file not found or invalid\");\n        return false;\n    }\n    \n    try\n    {\n        // In a real implementation, this would load the actual DDSP model\n        pImpl->ddspModel.loaded = true;\n        pImpl->ddspModel.sampleRate = 44100.0f;\n        \n        ddspInfo.isLoaded = true;\n        \n        if (onModelLoaded)\n            onModelLoaded(\"DDSP model loaded successfully\");\n            \n        return true;\n    }\n    catch (const std::exception& e)\n    {\n        lastError = AIError(AIError::ModelLoadFailed, \"Failed to load DDSP model: \" + juce::String(e.what()));\n        return false;\n    }\n}\n\nbool AIModelLoader::areModelsLoaded() const\n{\n    return crepeInfo.isLoaded && ddspInfo.isLoaded;\n}\n\nAIModelLoader::PitchPrediction AIModelLoader::predictPitch(const float* audioBuffer, int numSamples, float sampleRate)\n{\n    if (!pImpl->crepeModel.loaded)\n    {\n        lastError = AIError(AIError::ProcessingError, \"CREPE model not loaded\");\n        return PitchPrediction();\n    }\n    \n    auto startTime = juce::Time::getCurrentTime();\n    \n    // Preprocess audio for CREPE\n    std::vector<float> preprocessed = preprocessAudioForCrepe(audioBuffer, numSamples, sampleRate);\n    \n    // Predict using mock CREPE model\n    PitchPrediction result = pImpl->crepeModel.predict(preprocessed);\n    \n    // Update performance metrics\n    auto endTime = juce::Time::getCurrentTime();\n    lastProcessingTime = static_cast<float>((endTime - startTime).inMilliseconds());\n    updatePerformanceMetrics();\n    \n    return result;\n}\n\nstd::vector<AIModelLoader::PitchPrediction> AIModelLoader::predictPitchBatch(\n    const std::vector<std::vector<float>>& audioBuffers, float sampleRate)\n{\n    std::vector<PitchPrediction> results;\n    \n    if (!useMultiThreading || audioBuffers.size() <= 1)\n    {\n        // Process sequentially\n        for (const auto& buffer : audioBuffers)\n        {\n            results.push_back(predictPitch(buffer.data(), static_cast<int>(buffer.size()), sampleRate));\n        }\n    }\n    else\n    {\n        // Process in parallel\n        std::vector<std::future<PitchPrediction>> futures;\n        \n        for (const auto& buffer : audioBuffers)\n        {\n            futures.push_back(std::async(std::launch::async, [this, &buffer, sampleRate]()\n            {\n                return predictPitch(buffer.data(), static_cast<int>(buffer.size()), sampleRate);\n            }));\n        }\n        \n        for (auto& future : futures)\n        {\n            results.push_back(future.get());\n        }\n    }\n    \n    return results;\n}\n\nstd::vector<float> AIModelLoader::synthesizeAudio(const SynthesisParams& params, int numSamples, float sampleRate)\n{\n    if (!pImpl->ddspModel.loaded)\n    {\n        lastError = AIError(AIError::ProcessingError, \"DDSP model not loaded\");\n        return std::vector<float>(numSamples, 0.0f);\n    }\n    \n    auto startTime = juce::Time::getCurrentTime();\n    \n    // Synthesize using mock DDSP model\n    std::vector<float> result = pImpl->ddspModel.synthesize(params, numSamples);\n    \n    // Post-process output\n    postprocessDDSPOutput(result.data(), numSamples, 1.0f);\n    \n    // Update performance metrics\n    auto endTime = juce::Time::getCurrentTime();\n    lastProcessingTime = static_cast<float>((endTime - startTime).inMilliseconds());\n    updatePerformanceMetrics();\n    \n    return result;\n}\n\nbool AIModelLoader::processWithDDSP(const float* inputBuffer, float* outputBuffer, int numSamples, \n                                   const SynthesisParams& targetParams)\n{\n    if (!pImpl->ddspModel.loaded)\n    {\n        lastError = AIError(AIError::ProcessingError, \"DDSP model not loaded\");\n        return false;\n    }\n    \n    // Extract current synthesis parameters from input\n    SynthesisParams currentParams = extractSynthesisParams(inputBuffer, numSamples, 44100.0f);\n    \n    // Blend with target parameters based on processing quality\n    SynthesisParams blendedParams;\n    float blendFactor = 0.5f; // Could be adjusted based on quality settings\n    \n    blendedParams.fundamentalFreq = currentParams.fundamentalFreq * (1.0f - blendFactor) + \n                                   targetParams.fundamentalFreq * blendFactor;\n    blendedParams.loudness = currentParams.loudness * (1.0f - blendFactor) + \n                           targetParams.loudness * blendFactor;\n    \n    // Blend harmonic amplitudes\n    blendedParams.harmonicAmplitudes.resize(\n        std::max(currentParams.harmonicAmplitudes.size(), targetParams.harmonicAmplitudes.size()));\n    \n    for (size_t i = 0; i < blendedParams.harmonicAmplitudes.size(); ++i)\n    {\n        float current = i < currentParams.harmonicAmplitudes.size() ? currentParams.harmonicAmplitudes[i] : 0.0f;\n        float target = i < targetParams.harmonicAmplitudes.size() ? targetParams.harmonicAmplitudes[i] : 0.0f;\n        blendedParams.harmonicAmplitudes[i] = current * (1.0f - blendFactor) + target * blendFactor;\n    }\n    \n    // Synthesize output\n    std::vector<float> synthesized = synthesizeAudio(blendedParams, numSamples, 44100.0f);\n    \n    // Copy to output buffer\n    std::copy(synthesized.begin(), synthesized.end(), outputBuffer);\n    \n    return true;\n}\n\nvoid AIModelLoader::unloadModels()\n{\n    juce::ScopedLock lock(modelLock);\n    \n    pImpl->crepeModel.loaded = false;\n    pImpl->ddspModel.loaded = false;\n    \n    crepeInfo.isLoaded = false;\n    ddspInfo.isLoaded = false;\n    \n    clearError();\n}\n\nbool AIModelLoader::reloadModels()\n{\n    unloadModels();\n    \n    // Try to reload from the model directory\n    auto crepeFile = modelDirectory.getChildFile(\"crepe_model.onnx\");\n    auto ddspFile = modelDirectory.getChildFile(\"ddsp_model.onnx\");\n    \n    bool success = true;\n    if (crepeFile.existsAsFile())\n    {\n        success &= loadCrepeModel(crepeFile);\n    }\n    \n    if (ddspFile.existsAsFile())\n    {\n        success &= loadDDSPModel(ddspFile);\n    }\n    \n    return success;\n}\n\nvoid AIModelLoader::setModelDirectory(const juce::File& directory)\n{\n    modelDirectory = directory;\n    if (!modelDirectory.exists())\n    {\n        modelDirectory.createDirectory();\n    }\n}\n\nvoid AIModelLoader::setProcessingQuality(ProcessingQuality quality)\n{\n    currentQuality = quality;\n    \n    // Adjust model parameters based on quality\n    switch (quality)\n    {\n        case ProcessingQuality::Draft:\n            // Fastest processing, lower quality\n            break;\n        case ProcessingQuality::Standard:\n            // Balanced processing\n            break;\n        case ProcessingQuality::High:\n            // Higher quality, slower processing\n            break;\n        case ProcessingQuality::Ultra:\n            // Best quality, slowest processing\n            break;\n    }\n}\n\nvoid AIModelLoader::setUseMultiThreading(bool useThreads)\n{\n    useMultiThreading = useThreads;\n}\n\nvoid AIModelLoader::setMaxThreads(int threads)\n{\n    maxThreads = juce::jmax(1, threads);\n    threadPool.setNumThreads(maxThreads);\n}\n\nvoid AIModelLoader::setupDefaultModelDirectory()\n{\n    auto userDocsDir = juce::File::getSpecialLocation(juce::File::userDocumentsDirectory);\n    modelDirectory = userDocsDir.getChildFile(\"ProAutoTune\").getChildFile(\"Models\");\n    \n    if (!modelDirectory.exists())\n    {\n        modelDirectory.createDirectory();\n    }\n}\n\nbool AIModelLoader::validateModelFile(const juce::File& file, const juce::String& expectedType)\n{\n    if (!file.existsAsFile())\n        return false;\n    \n    // Basic validation - in a real implementation, this would check file format, headers, etc.\n    auto extension = file.getFileExtension().toLowerCase();\n    return extension == \".onnx\" || extension == \".pb\" || extension == \".tflite\";\n}\n\nstd::vector<float> AIModelLoader::preprocessAudioForCrepe(const float* input, int numSamples, float targetSampleRate)\n{\n    std::vector<float> output;\n    \n    if (targetSampleRate == crepeInfo.sampleRate)\n    {\n        // No resampling needed\n        output.assign(input, input + numSamples);\n    }\n    else\n    {\n        // Simple resampling (in real implementation, would use high-quality resampler)\n        float ratio = targetSampleRate / crepeInfo.sampleRate;\n        int newSize = static_cast<int>(numSamples / ratio);\n        output.resize(newSize);\n        \n        for (int i = 0; i < newSize; ++i)\n        {\n            float sourceIndex = i * ratio;\n            int index1 = static_cast<int>(sourceIndex);\n            int index2 = juce::jmin(index1 + 1, numSamples - 1);\n            float fraction = sourceIndex - index1;\n            \n            output[i] = input[index1] * (1.0f - fraction) + input[index2] * fraction;\n        }\n    }\n    \n    // Normalize\n    float maxAbs = 0.0f;\n    for (float sample : output)\n    {\n        maxAbs = juce::jmax(maxAbs, std::abs(sample));\n    }\n    \n    if (maxAbs > 0.0f)\n    {\n        float scale = 1.0f / maxAbs;\n        for (float& sample : output)\n        {\n            sample *= scale;\n        }\n    }\n    \n    return output;\n}\n\nAIModelLoader::SynthesisParams AIModelLoader::extractSynthesisParams(\n    const float* audioBuffer, int numSamples, float sampleRate)\n{\n    SynthesisParams params;\n    \n    // Extract fundamental frequency using simple peak picking\n    // (In real implementation, would use more sophisticated analysis)\n    \n    // Calculate RMS for loudness\n    float rms = 0.0f;\n    for (int i = 0; i < numSamples; ++i)\n    {\n        rms += audioBuffer[i] * audioBuffer[i];\n    }\n    rms = std::sqrt(rms / numSamples);\n    params.loudness = rms;\n    \n    // Mock fundamental frequency extraction\n    params.fundamentalFreq = 220.0f; // Default A3\n    \n    // Mock harmonic analysis - generate decreasing amplitudes\n    params.harmonicAmplitudes.resize(8);\n    for (int i = 0; i < 8; ++i)\n    {\n        params.harmonicAmplitudes[i] = rms * std::pow(0.7f, i);\n    }\n    \n    // Mock noise level\n    params.noiseLevel.resize(numSamples / 10); // Decimated noise envelope\n    for (size_t i = 0; i < params.noiseLevel.size(); ++i)\n    {\n        params.noiseLevel[i] = rms * 0.1f; // 10% noise level\n    }\n    \n    return params;\n}\n\nvoid AIModelLoader::postprocessDDSPOutput(float* output, int numSamples, float gainAdjustment)\n{\n    // Apply gain adjustment\n    for (int i = 0; i < numSamples; ++i)\n    {\n        output[i] *= gainAdjustment;\n        output[i] = juce::jlimit(-1.0f, 1.0f, output[i]); // Clip to prevent distortion\n    }\n    \n    // Apply soft limiting for more musical distortion\n    for (int i = 0; i < numSamples; ++i)\n    {\n        float x = output[i];\n        if (std::abs(x) > 0.8f)\n        {\n            output[i] = std::tanh(x * 1.2f) * 0.8f;\n        }\n    }\n}\n\nvoid AIModelLoader::updatePerformanceMetrics()\n{\n    processedFrames++;\n    \n    // Add to processing time history\n    pImpl->processingTimes.push_back(lastProcessingTime);\n    if (pImpl->processingTimes.size() > pImpl->maxHistorySize)\n    {\n        pImpl->processingTimes.erase(pImpl->processingTimes.begin());\n    }\n    \n    // Calculate average processing time\n    float sum = 0.0f;\n    for (float time : pImpl->processingTimes)\n    {\n        sum += time;\n    }\n    averageProcessingTime = sum / pImpl->processingTimes.size();\n}","size_bytes":17936},"Source/LookAndFeel.cpp":{"content":"#include \"LookAndFeel.h\"\n\n// Color definitions\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::background          = juce::Colour(0xff1e1e2e);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::surface             = juce::Colour(0xff2a2a3a);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::surfaceVariant      = juce::Colour(0xff2d2d44);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::primary             = juce::Colour(0xff4CAF50);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::primaryVariant      = juce::Colour(0xff388E3C);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::secondary           = juce::Colour(0xff03DAC6);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::accent              = juce::Colour(0xffFF6B35);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::textPrimary         = juce::Colour(0xffffffff);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::textSecondary       = juce::Colour(0xffb8b8c8);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::textDisabled        = juce::Colour(0xff666666);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::border              = juce::Colour(0xff3d3d5c);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::borderFocus         = juce::Colour(0xff4CAF50);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::highlight           = juce::Colour(0xff4CAF50);\nconst juce::Colour ProAutoTuneLookAndFeel::Colors::shadow              = juce::Colour(0x80000000);\n\nProAutoTuneLookAndFeel::ProAutoTuneLookAndFeel()\n{\n    // Set default colors\n    setColour(juce::ResizableWindow::backgroundColourId, Colors::background);\n    setColour(juce::DocumentWindow::backgroundColourId, Colors::background);\n    \n    // Slider colors\n    setColour(juce::Slider::backgroundColourId, Colors::surface);\n    setColour(juce::Slider::thumbColourId, Colors::primary);\n    setColour(juce::Slider::trackColourId, Colors::border);\n    setColour(juce::Slider::rotarySliderFillColourId, Colors::primary);\n    setColour(juce::Slider::rotarySliderOutlineColourId, Colors::border);\n    setColour(juce::Slider::textBoxBackgroundColourId, Colors::surface);\n    setColour(juce::Slider::textBoxTextColourId, Colors::textPrimary);\n    setColour(juce::Slider::textBoxOutlineColourId, Colors::border);\n    \n    // ComboBox colors\n    setColour(juce::ComboBox::backgroundColourId, Colors::surface);\n    setColour(juce::ComboBox::textColourId, Colors::textPrimary);\n    setColour(juce::ComboBox::outlineColourId, Colors::border);\n    setColour(juce::ComboBox::buttonColourId, Colors::surfaceVariant);\n    setColour(juce::ComboBox::arrowColourId, Colors::textSecondary);\n    \n    // Button colors\n    setColour(juce::TextButton::buttonColourId, Colors::surface);\n    setColour(juce::TextButton::textColourOffId, Colors::textPrimary);\n    setColour(juce::TextButton::textColourOnId, Colors::textPrimary);\n    \n    // Label colors\n    setColour(juce::Label::textColourId, Colors::textPrimary);\n    setColour(juce::Label::backgroundColourId, juce::Colours::transparentBlack);\n    \n    // PopupMenu colors\n    setColour(juce::PopupMenu::backgroundColourId, Colors::surface);\n    setColour(juce::PopupMenu::textColourId, Colors::textPrimary);\n    setColour(juce::PopupMenu::highlightedBackgroundColourId, Colors::primary);\n    setColour(juce::PopupMenu::highlightedTextColourId, Colors::textPrimary);\n}\n\nProAutoTuneLookAndFeel::~ProAutoTuneLookAndFeel()\n{\n}\n\nvoid ProAutoTuneLookAndFeel::drawRotarySlider(juce::Graphics& g, int x, int y, int width, int height,\n                                             float sliderPosProportional, float rotaryStartAngle,\n                                             float rotaryEndAngle, juce::Slider& slider)\n{\n    auto bounds = juce::Rectangle<float>(x, y, width, height).reduced(10.0f);\n    auto radius = juce::jmin(bounds.getWidth(), bounds.getHeight()) / 2.0f;\n    auto toAngle = rotaryStartAngle + sliderPosProportional * (rotaryEndAngle - rotaryStartAngle);\n    auto lineW = juce::jmin(8.0f, radius * 0.5f);\n    auto arcRadius = radius - lineW * 0.5f;\n    auto centre = bounds.getCentre();\n    \n    // Draw outer ring (track)\n    juce::Path backgroundArc;\n    backgroundArc.addCentredArc(centre.x, centre.y, arcRadius, arcRadius, 0.0f,\n                               rotaryStartAngle, rotaryEndAngle, true);\n    \n    g.setColour(Colors::border);\n    g.strokePath(backgroundArc, juce::PathStrokeType(lineW, juce::PathStrokeType::curved, juce::PathStrokeType::rounded));\n    \n    // Draw filled arc (value)\n    if (sliderPosProportional > 0.0f)\n    {\n        juce::Path valueArc;\n        valueArc.addCentredArc(centre.x, centre.y, arcRadius, arcRadius, 0.0f,\n                              rotaryStartAngle, toAngle, true);\n        \n        // Create gradient for the value arc\n        juce::ColourGradient gradient(Colors::primary, centre.x - radius, centre.y,\n                                     Colors::accent, centre.x + radius, centre.y, false);\n        g.setGradientFill(gradient);\n        g.strokePath(valueArc, juce::PathStrokeType(lineW, juce::PathStrokeType::curved, juce::PathStrokeType::rounded));\n    }\n    \n    // Draw inner circle\n    auto innerRadius = radius * 0.6f;\n    juce::Rectangle<float> innerCircle(centre.x - innerRadius, centre.y - innerRadius,\n                                      innerRadius * 2.0f, innerRadius * 2.0f);\n    \n    // Inner circle gradient\n    juce::ColourGradient innerGradient(Colors::surfaceVariant.brighter(0.2f), centre.x, centre.y - innerRadius,\n                                      Colors::surface.darker(0.3f), centre.x, centre.y + innerRadius, false);\n    g.setGradientFill(innerGradient);\n    g.fillEllipse(innerCircle);\n    \n    // Inner circle border\n    g.setColour(Colors::border);\n    g.drawEllipse(innerCircle, 2.0f);\n    \n    // Draw pointer\n    juce::Path pointer;\n    auto pointerLength = radius * 0.4f;\n    auto pointerThickness = 3.0f;\n    \n    pointer.addRectangle(-pointerThickness * 0.5f, -pointerLength + 5.0f, pointerThickness, pointerLength);\n    pointer.applyTransform(juce::AffineTransform::rotation(toAngle).translated(centre.x, centre.y));\n    \n    g.setColour(Colors::textPrimary);\n    g.fillPath(pointer);\n    \n    // Draw center dot\n    auto dotRadius = 4.0f;\n    g.setColour(Colors::primary);\n    g.fillEllipse(centre.x - dotRadius, centre.y - dotRadius, dotRadius * 2.0f, dotRadius * 2.0f);\n    \n    // Add glow effect when focused\n    if (slider.hasKeyboardFocus(false))\n    {\n        drawGlowEffect(g, bounds, Colors::primary, 0.8f);\n    }\n}\n\nvoid ProAutoTuneLookAndFeel::drawLinearSlider(juce::Graphics& g, int x, int y, int width, int height,\n                                             float sliderPos, float minSliderPos, float maxSliderPos,\n                                             const juce::Slider::SliderStyle style, juce::Slider& slider)\n{\n    auto trackWidth = juce::jmin(6.0f, (float)juce::jmin(width, height) * 0.25f);\n    juce::Point<float> startPoint, endPoint;\n    \n    if (style == juce::Slider::LinearHorizontal)\n    {\n        startPoint = {(float)x, (float)y + (float)height * 0.5f};\n        endPoint = {(float)(x + width), startPoint.y};\n    }\n    else\n    {\n        startPoint = {(float)x + (float)width * 0.5f, (float)(y + height)};\n        endPoint = {startPoint.x, (float)y};\n    }\n    \n    juce::Path track;\n    track.startNewSubPath(startPoint);\n    track.lineTo(endPoint);\n    g.setColour(Colors::border);\n    g.strokePath(track, {trackWidth, juce::PathStrokeType::curved, juce::PathStrokeType::rounded});\n    \n    juce::Path filledTrack;\n    filledTrack.startNewSubPath(startPoint);\n    filledTrack.lineTo({sliderPos, startPoint.y});\n    g.setColour(Colors::primary);\n    g.strokePath(filledTrack, {trackWidth, juce::PathStrokeType::curved, juce::PathStrokeType::rounded});\n    \n    // Draw thumb\n    auto thumbWidth = getSliderThumbRadius(slider);\n    g.setColour(Colors::primary);\n    g.fillEllipse(juce::Rectangle<float>(thumbWidth, thumbWidth).withCentre({sliderPos, startPoint.y}));\n    \n    g.setColour(Colors::textPrimary);\n    g.drawEllipse(juce::Rectangle<float>(thumbWidth, thumbWidth).withCentre({sliderPos, startPoint.y}), 1.0f);\n}\n\njuce::Label* ProAutoTuneLookAndFeel::createSliderTextBox(juce::Slider& slider)\n{\n    auto label = LookAndFeel_V4::createSliderTextBox(slider);\n    \n    label->setFont(getControlFont());\n    label->setJustificationType(juce::Justification::centred);\n    label->setColour(juce::Label::textColourId, Colors::textPrimary);\n    label->setColour(juce::Label::backgroundColourId, Colors::surface);\n    label->setColour(juce::Label::outlineColourId, Colors::border);\n    \n    return label;\n}\n\nvoid ProAutoTuneLookAndFeel::drawComboBox(juce::Graphics& g, int width, int height, bool isButtonDown,\n                                         int buttonX, int buttonY, int buttonW, int buttonH,\n                                         juce::ComboBox& comboBox)\n{\n    auto cornerSize = 6.0f;\n    auto bounds = juce::Rectangle<int>(0, 0, width, height).toFloat();\n    \n    // Background gradient\n    juce::ColourGradient gradient(Colors::surface.brighter(0.1f), 0.0f, 0.0f,\n                                 Colors::surface.darker(0.1f), 0.0f, (float)height, false);\n    g.setGradientFill(gradient);\n    g.fillRoundedRectangle(bounds, cornerSize);\n    \n    // Border\n    auto borderColor = comboBox.hasKeyboardFocus(false) ? Colors::borderFocus : Colors::border;\n    g.setColour(borderColor);\n    g.drawRoundedRectangle(bounds.reduced(0.5f), cornerSize, 1.0f);\n    \n    // Button area\n    auto buttonArea = juce::Rectangle<float>(buttonX, buttonY, buttonW, buttonH).reduced(2.0f);\n    \n    if (isButtonDown)\n    {\n        g.setColour(Colors::surfaceVariant.darker(0.2f));\n        g.fillRoundedRectangle(buttonArea, cornerSize * 0.5f);\n    }\n    \n    // Draw arrow\n    auto arrowArea = buttonArea.reduced(buttonArea.getWidth() * 0.3f, buttonArea.getHeight() * 0.3f);\n    juce::Path arrow;\n    arrow.addTriangle(arrowArea.getX(), arrowArea.getY(),\n                     arrowArea.getRight(), arrowArea.getY(),\n                     arrowArea.getCentreX(), arrowArea.getBottom());\n    \n    g.setColour(Colors::textSecondary);\n    g.fillPath(arrow);\n    \n    // Add subtle inner shadow\n    g.setColour(Colors::shadow.withAlpha(0.3f));\n    g.drawRoundedRectangle(bounds.reduced(1.0f), cornerSize - 1.0f, 1.0f);\n}\n\nvoid ProAutoTuneLookAndFeel::positionComboBoxText(juce::ComboBox& comboBox, juce::Label& labelToPosition)\n{\n    labelToPosition.setBounds(8, 1, comboBox.getWidth() - 30, comboBox.getHeight() - 2);\n    labelToPosition.setFont(getControlFont());\n    labelToPosition.setJustificationType(juce::Justification::centredLeft);\n}\n\nvoid ProAutoTuneLookAndFeel::drawButtonBackground(juce::Graphics& g, juce::Button& button,\n                                                 const juce::Colour& backgroundColour,\n                                                 bool shouldDrawButtonAsHighlighted,\n                                                 bool shouldDrawButtonAsDown)\n{\n    auto bounds = button.getLocalBounds().toFloat().reduced(1.0f);\n    auto cornerSize = 6.0f;\n    \n    juce::Colour baseColor = Colors::surface;\n    \n    if (shouldDrawButtonAsDown)\n    {\n        baseColor = Colors::surfaceVariant.darker(0.2f);\n    }\n    else if (shouldDrawButtonAsHighlighted)\n    {\n        baseColor = Colors::surfaceVariant.brighter(0.1f);\n    }\n    \n    // Background gradient\n    juce::ColourGradient gradient(baseColor.brighter(0.1f), bounds.getCentreX(), bounds.getY(),\n                                 baseColor.darker(0.1f), bounds.getCentreX(), bounds.getBottom(), false);\n    g.setGradientFill(gradient);\n    g.fillRoundedRectangle(bounds, cornerSize);\n    \n    // Border\n    juce::Colour borderColor = Colors::border;\n    if (button.hasKeyboardFocus(false))\n        borderColor = Colors::borderFocus;\n    \n    g.setColour(borderColor);\n    g.drawRoundedRectangle(bounds, cornerSize, 1.0f);\n    \n    // Inner highlight\n    if (shouldDrawButtonAsHighlighted && !shouldDrawButtonAsDown)\n    {\n        g.setColour(Colors::highlight.withAlpha(0.1f));\n        g.fillRoundedRectangle(bounds.reduced(1.0f), cornerSize - 1.0f);\n    }\n}\n\nvoid ProAutoTuneLookAndFeel::drawButtonText(juce::Graphics& g, juce::TextButton& button,\n                                           bool shouldDrawButtonAsHighlighted,\n                                           bool shouldDrawButtonAsDown)\n{\n    auto font = getControlFont();\n    g.setFont(font);\n    \n    juce::Colour textColor = Colors::textPrimary;\n    if (!button.isEnabled())\n        textColor = Colors::textDisabled;\n    \n    g.setColour(textColor);\n    \n    auto yIndent = juce::jmin(4, button.proportionOfHeight(0.3f));\n    auto cornerSize = juce::jmin(button.getHeight(), button.getWidth()) / 2;\n    auto fontHeight = juce::roundToInt(font.getHeight() * 0.6f);\n    auto leftIndent = juce::jmin(fontHeight, 2 + cornerSize / (button.isConnectedOnLeft() ? 4 : 2));\n    auto rightIndent = juce::jmin(fontHeight, 2 + cornerSize / (button.isConnectedOnRight() ? 4 : 2));\n    auto textWidth = button.getWidth() - leftIndent - rightIndent;\n    \n    if (textWidth > 0)\n    {\n        g.drawFittedText(button.getButtonText(),\n                        leftIndent, yIndent, textWidth, button.getHeight() - yIndent * 2,\n                        juce::Justification::centred, 2);\n    }\n}\n\nvoid ProAutoTuneLookAndFeel::drawLabel(juce::Graphics& g, juce::Label& label)\n{\n    g.fillAll(label.findColour(juce::Label::backgroundColourId));\n    \n    if (!label.isBeingEdited())\n    {\n        auto alpha = label.isEnabled() ? 1.0f : 0.5f;\n        const auto font = getLabelFont(label);\n        \n        g.setColour(label.findColour(juce::Label::textColourId).withMultipliedAlpha(alpha));\n        g.setFont(font);\n        \n        auto textArea = getLabelBorderSize(label).subtractedFrom(label.getLocalBounds());\n        \n        g.drawFittedText(label.getText(), textArea, label.getJustificationType(),\n                        juce::jmax(1, (int)((float)textArea.getHeight() / font.getHeight())),\n                        label.getMinimumHorizontalScale());\n        \n        g.setColour(label.findColour(juce::Label::outlineColourId).withMultipliedAlpha(alpha));\n    }\n    else if (label.isEnabled())\n    {\n        g.setColour(label.findColour(juce::Label::outlineColourId));\n    }\n    \n    g.drawRect(label.getLocalBounds());\n}\n\nvoid ProAutoTuneLookAndFeel::drawPopupMenuBackground(juce::Graphics& g, int width, int height)\n{\n    auto background = findColour(juce::PopupMenu::backgroundColourId);\n    g.fillAll(background);\n    \n    // Add subtle border\n    g.setColour(Colors::border);\n    g.drawRect(0, 0, width, height, 1);\n    \n    // Add drop shadow effect\n    juce::Path shadowPath;\n    shadowPath.addRoundedRectangle(2, 2, width - 4, height - 4, 4.0f);\n    juce::DropShadow shadow(Colors::shadow, 8, juce::Point<int>(0, 2));\n    shadow.drawForPath(g, shadowPath);\n}\n\nvoid ProAutoTuneLookAndFeel::drawPopupMenuItem(juce::Graphics& g, const juce::Rectangle<int>& area,\n                                              bool isSeparator, bool isActive, bool isHighlighted,\n                                              bool isTicked, bool hasSubMenu, const juce::String& text,\n                                              const juce::String& shortcutKeyText,\n                                              const juce::Drawable* icon, const juce::Colour* textColour)\n{\n    if (isSeparator)\n    {\n        auto r = area.reduced(5, 0);\n        r.removeFromTop(juce::roundToInt(((float)r.getHeight() * 0.5f) - 0.5f));\n        \n        g.setColour(Colors::border);\n        g.fillRect(r.removeFromTop(1));\n    }\n    else\n    {\n        auto textColor = (textColour == nullptr ? findColour(juce::PopupMenu::textColourId) : *textColour);\n        \n        auto maxFontHeight = (float)area.getHeight() / 1.3f;\n        \n        if (isHighlighted && isActive)\n        {\n            g.setColour(Colors::primary.withAlpha(0.8f));\n            g.fillRect(area.reduced(1));\n            \n            g.setColour(Colors::textPrimary);\n        }\n        else\n        {\n            g.setColour(textColor.withMultipliedAlpha(isActive ? 1.0f : 0.5f));\n        }\n        \n        g.setFont(getControlFont().withHeight(maxFontHeight));\n        \n        auto iconArea = area.reduced(5).removeFromLeft(juce::roundToInt(maxFontHeight)).toFloat();\n        \n        if (icon != nullptr)\n        {\n            icon->drawWithin(g, iconArea, juce::RectanglePlacement::centred | juce::RectanglePlacement::onlyReduceInSize, 1.0f);\n        }\n        else if (isTicked)\n        {\n            // Draw checkmark\n            juce::Path tick;\n            tick.startNewSubPath(iconArea.getX() + iconArea.getWidth() * 0.2f, iconArea.getCentreY());\n            tick.lineTo(iconArea.getCentreX(), iconArea.getY() + iconArea.getHeight() * 0.8f);\n            tick.lineTo(iconArea.getRight() - iconArea.getWidth() * 0.2f, iconArea.getY() + iconArea.getHeight() * 0.3f);\n            \n            g.strokePath(tick, juce::PathStrokeType(2.0f));\n        }\n        \n        if (hasSubMenu)\n        {\n            auto arrowH = 0.6f * getPopupMenuFont().getHeight();\n            auto x = (float)area.getRight() - arrowH * 1.0f;\n            auto halfH = (float)area.getHeight() * 0.5f;\n            \n            juce::Path path;\n            path.addTriangle(x, halfH - arrowH * 0.5f,\n                           x, halfH + arrowH * 0.5f,\n                           x + arrowH * 0.6f, halfH);\n            \n            g.fillPath(path);\n        }\n        \n        g.drawFittedText(text,\n                        area.reduced(iconArea.getWidth() + 5, 0),\n                        juce::Justification::centredLeft, 1);\n        \n        if (shortcutKeyText.isNotEmpty())\n        {\n            auto f2 = getControlFont().withHeight(maxFontHeight * 0.75f);\n            g.setFont(f2);\n            g.drawText(shortcutKeyText, area, juce::Justification::centredRight, true);\n        }\n    }\n}\n\nvoid ProAutoTuneLookAndFeel::drawGlowEffect(juce::Graphics& g, const juce::Rectangle<float>& bounds,\n                                           juce::Colour glowColor, float intensity)\n{\n    const int glowRadius = 10;\n    const float alpha = 0.3f * intensity;\n    \n    for (int i = 0; i < glowRadius; ++i)\n    {\n        float currentAlpha = alpha * (1.0f - static_cast<float>(i) / glowRadius);\n        g.setColour(glowColor.withAlpha(currentAlpha));\n        g.drawRoundedRectangle(bounds.expanded(i), 8.0f + i, 1.0f);\n    }\n}\n\nvoid ProAutoTuneLookAndFeel::drawGradientBackground(juce::Graphics& g, const juce::Rectangle<int>& bounds,\n                                                   juce::Colour topColor, juce::Colour bottomColor)\n{\n    juce::ColourGradient gradient(topColor, 0.0f, (float)bounds.getY(),\n                                 bottomColor, 0.0f, (float)bounds.getBottom(), false);\n    g.setGradientFill(gradient);\n    g.fillRect(bounds);\n}\n\nvoid ProAutoTuneLookAndFeel::drawRoundedPath(juce::Graphics& g, const juce::Path& path,\n                                            juce::Colour fillColor, juce::Colour strokeColor,\n                                            float strokeWidth)\n{\n    g.setColour(fillColor);\n    g.fillPath(path);\n    \n    if (strokeWidth > 0.0f)\n    {\n        g.setColour(strokeColor);\n        g.strokePath(path, juce::PathStrokeType(strokeWidth));\n    }\n}\n\njuce::Font ProAutoTuneLookAndFeel::getTitleFont() const\n{\n    return juce::Font(\"Arial\", 24.0f, juce::Font::bold);\n}\n\njuce::Font ProAutoTuneLookAndFeel::getControlFont() const\n{\n    return juce::Font(\"Arial\", 14.0f, juce::Font::plain);\n}\n\njuce::Font ProAutoTuneLookAndFeel::getSmallFont() const\n{\n    return juce::Font(\"Arial\", 12.0f, juce::Font::plain);\n}\n","size_bytes":19709},"Source/ModeSelector.cpp":{"content":"#include \"ModeSelector.h\"\n\nModeSelector::ModeSelector()\n    : currentMode(Parameters::Mode::Classic),\n      currentQuality(QualityLevel::High),\n      isInitialized(false)\n{\n    initializeModeConfigs();\n    isInitialized = true;\n}\n\nModeSelector::~ModeSelector()\n{\n}\n\nvoid ModeSelector::setCurrentMode(Parameters::Mode mode)\n{\n    if (mode != currentMode && canSwitchToMode(mode))\n    {\n        Parameters::Mode oldMode = currentMode;\n        currentMode = mode;\n        lastSwitchTime = juce::Time::getCurrentTime();\n        \n        if (onModeChanged)\n            onModeChanged(oldMode, currentMode);\n    }\n}\n\nconst ModeSelector::ModeConfig& ModeSelector::getCurrentModeConfig() const\n{\n    return getModeConfig(currentMode);\n}\n\nconst ModeSelector::ModeConfig& ModeSelector::getModeConfig(Parameters::Mode mode) const\n{\n    int index = static_cast<int>(mode);\n    if (index >= 0 && index < static_cast<int>(modeConfigs.size()))\n    {\n        return modeConfigs[index];\n    }\n    return modeConfigs[0]; // Default to Classic mode\n}\n\njuce::StringArray ModeSelector::getModeNames() const\n{\n    juce::StringArray names;\n    for (const auto& config : modeConfigs)\n    {\n        names.add(config.name);\n    }\n    return names;\n}\n\nModeSelector::ProcessingParams ModeSelector::getProcessingParams() const\n{\n    return getProcessingParams(currentMode);\n}\n\nModeSelector::ProcessingParams ModeSelector::getProcessingParams(Parameters::Mode mode) const\n{\n    const auto& config = getModeConfig(mode);\n    return calculateProcessingParams(config);\n}\n\nModeSelector::PitchAlgorithm ModeSelector::getPitchAlgorithm() const\n{\n    return getPitchAlgorithm(currentMode);\n}\n\nModeSelector::PitchAlgorithm ModeSelector::getPitchAlgorithm(Parameters::Mode mode) const\n{\n    switch (mode)\n    {\n        case Parameters::Mode::Classic:\n            return PitchAlgorithm::Autocorrelation;\n        case Parameters::Mode::Hard:\n            return PitchAlgorithm::YIN;\n        case Parameters::Mode::AI:\n            return PitchAlgorithm::Combined;\n        default:\n            return PitchAlgorithm::Autocorrelation;\n    }\n}\n\nModeSelector::QualityLevel ModeSelector::getQualityLevel() const\n{\n    return currentQuality;\n}\n\nvoid ModeSelector::setQualityLevel(QualityLevel level)\n{\n    currentQuality = level;\n}\n\nvoid ModeSelector::switchToMode(Parameters::Mode newMode)\n{\n    if (!validateModeSwitch(newMode))\n    {\n        if (onModeError)\n            onModeError(\"Cannot switch to mode: \" + getModeConfig(newMode).name);\n        return;\n    }\n    \n    setCurrentMode(newMode);\n}\n\nbool ModeSelector::canSwitchToMode(Parameters::Mode mode) const\n{\n    // Check if enough time has passed since last switch to prevent rapid switching\n    if (isInitialized && (juce::Time::getCurrentTime() - lastSwitchTime).inMilliseconds() < 100)\n    {\n        return false;\n    }\n    \n    // Check if mode is valid\n    int index = static_cast<int>(mode);\n    if (index < 0 || index >= static_cast<int>(modeConfigs.size()))\n    {\n        return false;\n    }\n    \n    return true;\n}\n\nModeSelector::PerformanceMetrics ModeSelector::getPerformanceMetrics() const\n{\n    return metrics;\n}\n\nvoid ModeSelector::updatePerformanceMetrics(float cpu, float latency, float accuracy)\n{\n    metrics.cpuUsage = cpu;\n    metrics.latency = latency;\n    metrics.accuracy = accuracy;\n    \n    // Determine if real-time capable based on current metrics\n    const auto& config = getCurrentModeConfig();\n    metrics.realTimeCapable = (latency <= config.latencyMs * 1.5f) && (cpu <= 80.0f);\n}\n\nvoid ModeSelector::initializeModeConfigs()\n{\n    // Classic Mode - Traditional auto-tune with smooth correction\n    modeConfigs[0] = ModeConfig(\n        \"Classic\",\n        \"Traditional smooth pitch correction with natural sound\",\n        50.0f,  // Default speed\n        50.0f,  // Default amount\n        false,  // Formant preservation (basic)\n        false,  // Advanced pitch detection\n        false,  // Rubber Band\n        8.0f    // Latency in ms\n    );\n    \n    // Hard Mode - Aggressive T-Pain style correction\n    modeConfigs[1] = ModeConfig(\n        \"Hard\",\n        \"Aggressive pitch correction with immediate snapping\",\n        90.0f,  // Default speed (fast)\n        85.0f,  // Default amount (strong)\n        false,  // Formant preservation (not needed for effect)\n        true,   // Advanced pitch detection (YIN for accuracy)\n        false,  // Rubber Band (not needed for hard correction)\n        5.0f    // Latency in ms (very responsive)\n    );\n    \n    // AI Mode - Advanced processing with formant preservation\n    modeConfigs[2] = ModeConfig(\n        \"AI\",\n        \"AI-powered natural correction with formant preservation\",\n        25.0f,  // Default speed (slow and natural)\n        60.0f,  // Default amount (moderate)\n        true,   // Formant preservation (essential for natural sound)\n        true,   // Advanced pitch detection (combined algorithms)\n        true,   // Rubber Band (high quality processing)\n        15.0f   // Latency in ms (higher due to advanced processing)\n    );\n}\n\nModeSelector::ProcessingParams ModeSelector::calculateProcessingParams(const ModeConfig& config) const\n{\n    ProcessingParams params;\n    \n    // Base parameters from mode config\n    params.speedMultiplier = config.defaultSpeed / 50.0f; // Normalize to 50% base\n    params.amountMultiplier = config.defaultAmount / 50.0f;\n    \n    // Adjust based on current mode\n    switch (currentMode)\n    {\n        case Parameters::Mode::Classic:\n            params.smoothingFactor = 0.8f;\n            params.windowSize = 2048;\n            params.hopSize = 512;\n            params.enableFormantCorrection = false;\n            params.enableHarmonicAnalysis = false;\n            break;\n            \n        case Parameters::Mode::Hard:\n            params.smoothingFactor = 0.2f; // Less smoothing for immediate response\n            params.windowSize = 1024;      // Smaller window for lower latency\n            params.hopSize = 256;          // Smaller hop for faster response\n            params.enableFormantCorrection = false;\n            params.enableHarmonicAnalysis = true; // For better pitch detection\n            break;\n            \n        case Parameters::Mode::AI:\n            params.smoothingFactor = 0.9f; // More smoothing for natural sound\n            params.windowSize = 4096;      // Larger window for better analysis\n            params.hopSize = 1024;         // Larger hop acceptable for quality\n            params.enableFormantCorrection = true;\n            params.enableHarmonicAnalysis = true;\n            break;\n    }\n    \n    // Adjust based on quality level\n    switch (currentQuality)\n    {\n        case QualityLevel::Draft:\n            params.windowSize /= 2;\n            params.hopSize /= 2;\n            params.enableFormantCorrection = false;\n            break;\n            \n        case QualityLevel::Good:\n            // Use base settings\n            break;\n            \n        case QualityLevel::High:\n            // Use base settings with enhancements\n            if (currentMode == Parameters::Mode::AI)\n            {\n                params.smoothingFactor *= 1.1f;\n            }\n            break;\n            \n        case QualityLevel::Ultra:\n            params.windowSize *= 2;\n            params.enableFormantCorrection = true;\n            params.enableHarmonicAnalysis = true;\n            params.smoothingFactor = juce::jmin(0.95f, params.smoothingFactor * 1.2f);\n            break;\n    }\n    \n    return params;\n}\n\nbool ModeSelector::validateModeSwitch(Parameters::Mode newMode) const\n{\n    // Basic validation\n    if (!canSwitchToMode(newMode))\n        return false;\n    \n    // Check if we have the required resources for the new mode\n    const auto& config = getModeConfig(newMode);\n    \n    // AI mode requires more CPU - check if system can handle it\n    if (newMode == Parameters::Mode::AI && metrics.cpuUsage > 70.0f)\n    {\n        return false; // System might be too loaded for AI mode\n    }\n    \n    // Hard mode requires low latency - check if achievable\n    if (newMode == Parameters::Mode::Hard && metrics.latency > 20.0f)\n    {\n        return false; // Current latency too high for hard mode\n    }\n    \n    return true;\n}\n","size_bytes":8201},"Source/Parameters.cpp":{"content":"#include \"Parameters.h\"\n\n// Parameter ID strings\nconst juce::String Parameters::SPEED_ID = \"speed\";\nconst juce::String Parameters::AMOUNT_ID = \"amount\";\nconst juce::String Parameters::MODE_ID = \"mode\";\nconst juce::String Parameters::KEY_ID = \"key\";\nconst juce::String Parameters::SCALE_ID = \"scale\";\n\nParameters::Parameters()\n{\n}\n\nParameters::~Parameters()\n{\n}\n\njuce::AudioProcessorValueTreeState::ParameterLayout Parameters::createParameterLayout()\n{\n    std::vector<std::unique_ptr<juce::RangedAudioParameter>> params;\n\n    // Speed parameter - Controls how fast the correction is applied\n    params.push_back(std::make_unique<juce::AudioParameterFloat>(\n        SPEED_ID,\n        \"Speed\",\n        juce::NormalisableRange<float>(SPEED_MIN, SPEED_MAX, SPEED_STEP),\n        SPEED_DEFAULT,\n        juce::String(),\n        juce::AudioProcessorParameter::genericParameter,\n        [](float value, int) { return juce::String(value, 1) + \"%\"; }\n    ));\n\n    // Amount parameter - Controls the strength of the correction\n    params.push_back(std::make_unique<juce::AudioParameterFloat>(\n        AMOUNT_ID,\n        \"Amount\",\n        juce::NormalisableRange<float>(AMOUNT_MIN, AMOUNT_MAX, AMOUNT_STEP),\n        AMOUNT_DEFAULT,\n        juce::String(),\n        juce::AudioProcessorParameter::genericParameter,\n        [](float value, int) { return juce::String(value, 1) + \"%\"; }\n    ));\n\n    // Mode parameter - Selects the correction algorithm\n    juce::StringArray modeChoices;\n    modeChoices.add(\"Classic\");\n    modeChoices.add(\"Hard\");\n    modeChoices.add(\"AI\");\n\n    params.push_back(std::make_unique<juce::AudioParameterChoice>(\n        MODE_ID,\n        \"Mode\",\n        modeChoices,\n        MODE_DEFAULT\n    ));\n\n    // Key parameter - Sets the musical key\n    juce::StringArray keyChoices;\n    keyChoices.add(\"C\");\n    keyChoices.add(\"C#\");\n    keyChoices.add(\"D\");\n    keyChoices.add(\"D#\");\n    keyChoices.add(\"E\");\n    keyChoices.add(\"F\");\n    keyChoices.add(\"F#\");\n    keyChoices.add(\"G\");\n    keyChoices.add(\"G#\");\n    keyChoices.add(\"A\");\n    keyChoices.add(\"A#\");\n    keyChoices.add(\"B\");\n\n    params.push_back(std::make_unique<juce::AudioParameterChoice>(\n        KEY_ID,\n        \"Key\",\n        keyChoices,\n        KEY_DEFAULT\n    ));\n\n    // Scale parameter - Sets the musical scale\n    juce::StringArray scaleChoices;\n    scaleChoices.add(\"Major\");\n    scaleChoices.add(\"Minor\");\n    scaleChoices.add(\"Chromatic\");\n\n    params.push_back(std::make_unique<juce::AudioParameterChoice>(\n        SCALE_ID,\n        \"Scale\",\n        scaleChoices,\n        SCALE_DEFAULT\n    ));\n\n    return { params.begin(), params.end() };\n}\n\njuce::String Parameters::getModeString(Mode mode)\n{\n    switch (mode)\n    {\n        case Mode::Classic: return \"Classic\";\n        case Mode::Hard: return \"Hard\";\n        case Mode::AI: return \"AI\";\n        default: return \"Classic\";\n    }\n}\n\njuce::String Parameters::getKeyString(Key key)\n{\n    const char* keyNames[] = {\n        \"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \n        \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"\n    };\n    \n    int keyIndex = static_cast<int>(key);\n    if (keyIndex >= 0 && keyIndex < 12)\n    {\n        return juce::String(keyNames[keyIndex]);\n    }\n    \n    return \"C\";\n}\n\njuce::String Parameters::getScaleString(Scale scale)\n{\n    switch (scale)\n    {\n        case Scale::Major: return \"Major\";\n        case Scale::Minor: return \"Minor\";\n        case Scale::Chromatic: return \"Chromatic\";\n        default: return \"Major\";\n    }\n}\n\nParameters::Mode Parameters::getMode(int value)\n{\n    if (value >= 0 && value <= 2)\n        return static_cast<Mode>(value);\n    return Mode::Classic;\n}\n\nParameters::Key Parameters::getKey(int value)\n{\n    if (value >= 0 && value <= 11)\n        return static_cast<Key>(value);\n    return Key::C;\n}\n\nParameters::Scale Parameters::getScale(int value)\n{\n    if (value >= 0 && value <= 2)\n        return static_cast<Scale>(value);\n    return Scale::Major;\n}\n\nconst std::vector<int>& Parameters::getMajorScale()\n{\n    static const std::vector<int> majorScale = {0, 2, 4, 5, 7, 9, 11}; // Major scale intervals\n    return majorScale;\n}\n\nconst std::vector<int>& Parameters::getMinorScale()\n{\n    static const std::vector<int> minorScale = {0, 2, 3, 5, 7, 8, 10}; // Natural minor scale intervals\n    return minorScale;\n}\n\nconst std::vector<int>& Parameters::getChromaticScale()\n{\n    static const std::vector<int> chromaticScale = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}; // All semitones\n    return chromaticScale;\n}\n\nconst std::vector<int>& Parameters::getScaleNotes(Scale scale)\n{\n    switch (scale)\n    {\n        case Scale::Major: return getMajorScale();\n        case Scale::Minor: return getMinorScale();\n        case Scale::Chromatic: return getChromaticScale();\n        default: return getMajorScale();\n    }\n}\n","size_bytes":4779},"Source/PitchCorrectionEngine.cpp":{"content":"#include \"PitchCorrectionEngine.h\"\n#include \"Utils.h\"\n#include <algorithm>\n#include <cmath>\n\nPitchCorrectionEngine::PitchCorrectionEngine()\n{\n    // Initialize FFT\n    fft = std::make_unique<juce::dsp::FFT>(fftOrder);\n    window = std::make_unique<juce::dsp::WindowingFunction<float>>(fftSize, juce::dsp::WindowingFunction<float>::hann);\n    \n    // Allocate frequency domain buffer\n    frequencyData.allocate(fftSize, true);\n    magnitudeSpectrum.resize(fftSize / 2);\n    \n    // Initialize pitch history\n    pitchHistory.resize(pitchHistoryLength, 0.0f);\n    \n    // Initialize formant arrays\n    formantFrequencies.resize(maxFormants, 0.0f);\n    formantAmplitudes.resize(maxFormants, 0.0f);\n    \n    // Initialize grain buffer\n    grainBuffer.reserve(32); // Reserve space for grains\n}\n\nPitchCorrectionEngine::~PitchCorrectionEngine()\n{\n}\n\nvoid PitchCorrectionEngine::prepare(double newSampleRate, int newBlockSize)\n{\n    sampleRate = newSampleRate;\n    blockSize = newBlockSize;\n    \n    // Resize buffers\n    autocorrelationBuffer.resize(blockSize * 2);\n    windowedBuffer.resize(fftSize);\n    tempBuffer.resize(blockSize);\n    \n    // Calculate grain parameters based on sample rate\n    grainSize = static_cast<int>(sampleRate * 0.025); // 25ms grains\n    hopSize = grainSize / 4; // 75% overlap\n    \n    reset();\n}\n\nvoid PitchCorrectionEngine::reset()\n{\n    currentPitch = 0.0f;\n    pitchConfidence = 0.0f;\n    rmsLevel = 0.0f;\n    \n    std::fill(pitchHistory.begin(), pitchHistory.end(), 0.0f);\n    std::fill(formantFrequencies.begin(), formantFrequencies.end(), 0.0f);\n    std::fill(formantAmplitudes.begin(), formantAmplitudes.end(), 0.0f);\n    \n    grainBuffer.clear();\n}\n\nvoid PitchCorrectionEngine::detectPitch(const float* inputBuffer, int numSamples, float* pitchOutput)\n{\n    // Use autocorrelation-based pitch detection for basic mode\n    for (int i = 0; i < numSamples; ++i)\n    {\n        if (i % 256 == 0) // Update pitch every 256 samples for efficiency\n        {\n            int analysisSize = std::min(1024, numSamples - i);\n            currentPitch = detectPitchAutocorrelation(&inputBuffer[i], analysisSize);\n            smoothPitch(currentPitch);\n            rmsLevel = calculateRMS(&inputBuffer[i], analysisSize);\n        }\n        \n        pitchOutput[i] = currentPitch;\n    }\n}\n\nvoid PitchCorrectionEngine::detectPitchAdvanced(const float* inputBuffer, int numSamples, float* pitchOutput)\n{\n    // Use multiple algorithms and combine results for AI mode\n    for (int i = 0; i < numSamples; ++i)\n    {\n        if (i % 128 == 0) // More frequent updates for AI mode\n        {\n            int analysisSize = std::min(2048, numSamples - i);\n            \n            // Get pitches from different algorithms\n            float autoPitch = detectPitchAutocorrelation(&inputBuffer[i], analysisSize);\n            float yinPitch = detectPitchYIN(&inputBuffer[i], analysisSize);\n            float spectralPitch = detectPitchSpectral(&inputBuffer[i], analysisSize);\n            float harmonicPitch = detectPitchHarmonic(&inputBuffer[i], analysisSize);\n            \n            // Combine results with confidence weighting\n            std::vector<float> pitches = {autoPitch, yinPitch, spectralPitch, harmonicPitch};\n            std::vector<float> weights = {0.2f, 0.3f, 0.3f, 0.2f}; // YIN and spectral get more weight\n            \n            float combinedPitch = 0.0f;\n            float totalWeight = 0.0f;\n            \n            for (size_t j = 0; j < pitches.size(); ++j)\n            {\n                if (pitches[j] > 0.0f) // Valid pitch\n                {\n                    combinedPitch += pitches[j] * weights[j];\n                    totalWeight += weights[j];\n                }\n            }\n            \n            if (totalWeight > 0.0f)\n            {\n                currentPitch = combinedPitch / totalWeight;\n                smoothPitch(currentPitch);\n            }\n            \n            rmsLevel = calculateRMS(&inputBuffer[i], analysisSize);\n            analyzeSpectrum(&inputBuffer[i], analysisSize);\n        }\n        \n        pitchOutput[i] = currentPitch;\n    }\n}\n\nfloat PitchCorrectionEngine::detectPitchAutocorrelation(const float* buffer, int numSamples)\n{\n    if (numSamples < 64) return 0.0f;\n    \n    // Copy to windowed buffer and apply window\n    int analysisSize = std::min(numSamples, static_cast<int>(windowedBuffer.size()));\n    std::copy(buffer, buffer + analysisSize, windowedBuffer.begin());\n    applyHannWindow(windowedBuffer.data(), analysisSize);\n    \n    // Calculate autocorrelation\n    std::fill(autocorrelationBuffer.begin(), autocorrelationBuffer.end(), 0.0f);\n    \n    for (int lag = 1; lag < analysisSize / 2; ++lag)\n    {\n        for (int i = 0; i < analysisSize - lag; ++i)\n        {\n            autocorrelationBuffer[lag] += windowedBuffer[i] * windowedBuffer[i + lag];\n        }\n        autocorrelationBuffer[lag] /= (analysisSize - lag); // Normalize\n    }\n    \n    // Find peak in autocorrelation\n    float maxValue = 0.0f;\n    int maxLag = 0;\n    int minLag = static_cast<int>(sampleRate / 800.0); // Min freq ~800Hz\n    int maxLagLimit = static_cast<int>(sampleRate / 50.0); // Max freq ~50Hz\n    \n    for (int lag = minLag; lag < maxLagLimit && lag < autocorrelationBuffer.size(); ++lag)\n    {\n        if (autocorrelationBuffer[lag] > maxValue)\n        {\n            maxValue = autocorrelationBuffer[lag];\n            maxLag = lag;\n        }\n    }\n    \n    if (maxLag > 0 && maxValue > 0.3f) // Confidence threshold\n    {\n        // Parabolic interpolation for sub-sample accuracy\n        if (maxLag > 1 && maxLag < autocorrelationBuffer.size() - 1)\n        {\n            float y1 = autocorrelationBuffer[maxLag - 1];\n            float y2 = autocorrelationBuffer[maxLag];\n            float y3 = autocorrelationBuffer[maxLag + 1];\n            \n            float a = (y1 - 2*y2 + y3) / 2.0f;\n            if (std::abs(a) > 1e-6f)\n            {\n                float peak = -0.5f * (y3 - y1) / a;\n                float trueLag = maxLag + peak;\n                pitchConfidence = maxValue;\n                return static_cast<float>(sampleRate / trueLag);\n            }\n        }\n        \n        pitchConfidence = maxValue;\n        return static_cast<float>(sampleRate / maxLag);\n    }\n    \n    pitchConfidence = 0.0f;\n    return 0.0f;\n}\n\nfloat PitchCorrectionEngine::detectPitchYIN(const float* buffer, int numSamples)\n{\n    // Simplified YIN algorithm implementation\n    if (numSamples < 128) return 0.0f;\n    \n    int bufferSize = std::min(numSamples, 2048);\n    std::vector<float> yinBuffer(bufferSize / 2, 0.0f);\n    \n    // Step 1: Difference function\n    for (int tau = 1; tau < bufferSize / 2; ++tau)\n    {\n        for (int i = 0; i < bufferSize / 2; ++i)\n        {\n            float delta = buffer[i] - buffer[i + tau];\n            yinBuffer[tau] += delta * delta;\n        }\n    }\n    \n    // Step 2: Cumulative mean normalized difference\n    yinBuffer[0] = 1.0f;\n    float runningSum = 0.0f;\n    for (int tau = 1; tau < bufferSize / 2; ++tau)\n    {\n        runningSum += yinBuffer[tau];\n        if (runningSum > 0.0f)\n        {\n            yinBuffer[tau] *= tau / runningSum;\n        }\n        else\n        {\n            yinBuffer[tau] = 1.0f;\n        }\n    }\n    \n    // Step 3: Absolute threshold\n    const float threshold = 0.1f;\n    int minTau = static_cast<int>(sampleRate / 800.0);\n    int maxTau = static_cast<int>(sampleRate / 50.0);\n    \n    for (int tau = minTau; tau < maxTau && tau < yinBuffer.size(); ++tau)\n    {\n        if (yinBuffer[tau] < threshold)\n        {\n            // Step 4: Parabolic interpolation\n            while (tau + 1 < yinBuffer.size() && yinBuffer[tau + 1] < yinBuffer[tau])\n            {\n                tau++;\n            }\n            \n            // Interpolation\n            if (tau > 0 && tau < yinBuffer.size() - 1)\n            {\n                float s0 = yinBuffer[tau - 1];\n                float s1 = yinBuffer[tau];\n                float s2 = yinBuffer[tau + 1];\n                \n                float betterTau = tau + (s2 - s0) / (2.0f * (2.0f * s1 - s2 - s0));\n                return static_cast<float>(sampleRate / betterTau);\n            }\n            \n            return static_cast<float>(sampleRate / tau);\n        }\n    }\n    \n    return 0.0f;\n}\n\nfloat PitchCorrectionEngine::detectPitchSpectral(const float* buffer, int numSamples)\n{\n    if (numSamples < fftSize) return 0.0f;\n    \n    // Prepare FFT input\n    std::fill(windowedBuffer.begin(), windowedBuffer.end(), 0.0f);\n    std::copy(buffer, buffer + std::min(numSamples, fftSize), windowedBuffer.begin());\n    \n    // Apply window\n    window->multiplyWithWindowingTable(windowedBuffer.data(), fftSize);\n    \n    // Convert to complex and perform FFT\n    for (int i = 0; i < fftSize; ++i)\n    {\n        frequencyData[i] = juce::dsp::Complex<float>(windowedBuffer[i], 0.0f);\n    }\n    \n    fft->perform(frequencyData, frequencyData, false);\n    \n    // Calculate magnitude spectrum\n    for (int i = 0; i < fftSize / 2; ++i)\n    {\n        magnitudeSpectrum[i] = std::abs(frequencyData[i]);\n    }\n    \n    // Find peak in magnitude spectrum\n    float maxMag = 0.0f;\n    int peakBin = 0;\n    int minBin = static_cast<int>(50.0f * fftSize / sampleRate); // 50Hz minimum\n    int maxBin = static_cast<int>(800.0f * fftSize / sampleRate); // 800Hz maximum\n    \n    for (int i = minBin; i < maxBin && i < magnitudeSpectrum.size(); ++i)\n    {\n        if (magnitudeSpectrum[i] > maxMag)\n        {\n            maxMag = magnitudeSpectrum[i];\n            peakBin = i;\n        }\n    }\n    \n    if (peakBin > 0 && maxMag > 0.01f)\n    {\n        // Parabolic interpolation for better frequency resolution\n        if (peakBin > 1 && peakBin < magnitudeSpectrum.size() - 1)\n        {\n            float y1 = magnitudeSpectrum[peakBin - 1];\n            float y2 = magnitudeSpectrum[peakBin];\n            float y3 = magnitudeSpectrum[peakBin + 1];\n            \n            float a = (y1 - 2*y2 + y3) / 2.0f;\n            if (std::abs(a) > 1e-6f)\n            {\n                float peak = -0.5f * (y3 - y1) / a;\n                float trueBin = peakBin + peak;\n                return static_cast<float>(trueBin * sampleRate / fftSize);\n            }\n        }\n        \n        return static_cast<float>(peakBin * sampleRate / fftSize);\n    }\n    \n    return 0.0f;\n}\n\nfloat PitchCorrectionEngine::detectPitchHarmonic(const float* buffer, int numSamples)\n{\n    // Harmonic product spectrum method\n    if (numSamples < fftSize) return 0.0f;\n    \n    // Use existing spectrum from spectral method\n    analyzeSpectrum(buffer, numSamples);\n    \n    std::vector<float> hps(magnitudeSpectrum.size());\n    std::copy(magnitudeSpectrum.begin(), magnitudeSpectrum.end(), hps.begin());\n    \n    // Multiply spectrum with its decimated versions\n    const int maxHarmonics = 5;\n    for (int harmonic = 2; harmonic <= maxHarmonics; ++harmonic)\n    {\n        for (size_t i = 0; i < hps.size() / harmonic; ++i)\n        {\n            hps[i] *= magnitudeSpectrum[i * harmonic];\n        }\n    }\n    \n    // Find peak in HPS\n    float maxValue = 0.0f;\n    int peakBin = 0;\n    int minBin = static_cast<int>(50.0f * fftSize / sampleRate);\n    int maxBin = static_cast<int>(800.0f * fftSize / sampleRate);\n    \n    for (int i = minBin; i < maxBin && i < hps.size(); ++i)\n    {\n        if (hps[i] > maxValue)\n        {\n            maxValue = hps[i];\n            peakBin = i;\n        }\n    }\n    \n    if (peakBin > 0)\n    {\n        return static_cast<float>(peakBin * sampleRate / fftSize);\n    }\n    \n    return 0.0f;\n}\n\nvoid PitchCorrectionEngine::analyzeSpectrum(const float* buffer, int numSamples)\n{\n    // This would be called from detectPitchSpectral, so just ensure spectrum is available\n    detectPitchSpectral(buffer, numSamples);\n    detectFormants(magnitudeSpectrum);\n}\n\nvoid PitchCorrectionEngine::detectFormants(const std::vector<float>& spectrum)\n{\n    // Simple formant detection using peak picking\n    std::fill(formantFrequencies.begin(), formantFrequencies.end(), 0.0f);\n    std::fill(formantAmplitudes.begin(), formantAmplitudes.end(), 0.0f);\n    \n    // Look for peaks in the spectrum\n    std::vector<std::pair<float, int>> peaks;\n    \n    for (int i = 2; i < static_cast<int>(spectrum.size()) - 2; ++i)\n    {\n        float freq = static_cast<float>(i * sampleRate / fftSize);\n        if (freq > 200.0f && freq < 4000.0f) // Typical formant range\n        {\n            if (spectrum[i] > spectrum[i-1] && spectrum[i] > spectrum[i+1] &&\n                spectrum[i] > spectrum[i-2] && spectrum[i] > spectrum[i+2])\n            {\n                peaks.push_back({spectrum[i], i});\n            }\n        }\n    }\n    \n    // Sort peaks by amplitude\n    std::sort(peaks.begin(), peaks.end(), std::greater<std::pair<float, int>>());\n    \n    // Take the top formants\n    for (int i = 0; i < std::min(maxFormants, static_cast<int>(peaks.size())); ++i)\n    {\n        formantAmplitudes[i] = peaks[i].first;\n        formantFrequencies[i] = static_cast<float>(peaks[i].second * sampleRate / fftSize);\n    }\n}\n\nvoid PitchCorrectionEngine::correctPitch(float* buffer, int numSamples, \n                                        float targetPitch, float speed, float amount)\n{\n    if (currentPitch <= 0.0f || targetPitch <= 0.0f) return;\n    \n    float pitchRatio = targetPitch / currentPitch;\n    float correction = (pitchRatio - 1.0f) * amount * 0.01f; // Scale amount\n    \n    // Apply simple pitch shifting using interpolation\n    for (int i = 0; i < numSamples; ++i)\n    {\n        float smoothedCorrection = interpolateValue(0.0f, correction, speed * 0.01f);\n        buffer[i] *= (1.0f + smoothedCorrection);\n    }\n}\n\nvoid PitchCorrectionEngine::correctPitchHard(float* buffer, int numSamples, \n                                            float targetPitch, float speed, float amount)\n{\n    if (currentPitch <= 0.0f || targetPitch <= 0.0f) return;\n    \n    float pitchRatio = targetPitch / currentPitch;\n    float correction = (pitchRatio - 1.0f) * amount * 0.01f;\n    \n    // Hard correction with immediate snapping\n    float hardSpeed = juce::jmin(speed * 0.1f, 1.0f);\n    \n    for (int i = 0; i < numSamples; ++i)\n    {\n        // Immediate correction for hard mode\n        buffer[i] *= (1.0f + correction * hardSpeed);\n    }\n}\n\nvoid PitchCorrectionEngine::correctPitchAI(float* buffer, int numSamples, \n                                          float targetPitch, float speed, float amount)\n{\n    // AI mode with formant preservation and natural correction\n    if (currentPitch <= 0.0f || targetPitch <= 0.0f) return;\n    \n    float pitchRatio = targetPitch / currentPitch;\n    \n    // Preserve formants during pitch shifting\n    preserveFormants(buffer, numSamples, pitchRatio);\n    \n    // Apply smooth, natural correction\n    float correction = (pitchRatio - 1.0f) * amount * 0.01f;\n    float naturalSpeed = speed * 0.005f; // Slower, more natural correction\n    \n    for (int i = 0; i < numSamples; ++i)\n    {\n        float smoothCorrection = interpolateValue(0.0f, correction, naturalSpeed);\n        buffer[i] *= (1.0f + smoothCorrection);\n    }\n}\n\nvoid PitchCorrectionEngine::preserveFormants(float* buffer, int numSamples, float pitchShiftRatio)\n{\n    // Simplified formant preservation\n    // In a full implementation, this would involve spectral envelope manipulation\n    \n    if (pitchShiftRatio == 1.0f) return;\n    \n    // Apply spectral processing to preserve formant structure\n    // This is a simplified approach - real formant preservation requires\n    // more sophisticated spectral manipulation\n    \n    for (int i = 0; i < numSamples; ++i)\n    {\n        // Apply slight formant compensation\n        float compensation = 1.0f - (pitchShiftRatio - 1.0f) * 0.3f;\n        buffer[i] *= compensation;\n    }\n}\n\nfloat PitchCorrectionEngine::calculateRMS(const float* buffer, int numSamples)\n{\n    if (numSamples <= 0) return 0.0f;\n    \n    float sum = 0.0f;\n    for (int i = 0; i < numSamples; ++i)\n    {\n        sum += buffer[i] * buffer[i];\n    }\n    \n    return std::sqrt(sum / numSamples);\n}\n\nfloat PitchCorrectionEngine::calculateCentroid(const std::vector<float>& spectrum)\n{\n    float numerator = 0.0f;\n    float denominator = 0.0f;\n    \n    for (size_t i = 1; i < spectrum.size(); ++i)\n    {\n        float freq = static_cast<float>(i * sampleRate / fftSize);\n        numerator += freq * spectrum[i];\n        denominator += spectrum[i];\n    }\n    \n    return denominator > 0.0f ? numerator / denominator : 0.0f;\n}\n\nvoid PitchCorrectionEngine::smoothPitch(float newPitch)\n{\n    if (newPitch > 0.0f)\n    {\n        // Add to history\n        for (int i = 0; i < pitchHistoryLength - 1; ++i)\n        {\n            pitchHistory[i] = pitchHistory[i + 1];\n        }\n        pitchHistory.back() = newPitch;\n        \n        // Calculate smoothed pitch\n        float smoothedPitch = 0.0f;\n        float totalWeight = 0.0f;\n        \n        for (size_t i = 0; i < static_cast<size_t>(pitchHistoryLength); ++i)\n        {\n            if (pitchHistory[i] > 0.0f)\n            {\n                float weight = static_cast<float>(i + 1) / pitchHistoryLength;\n                smoothedPitch += pitchHistory[i] * weight;\n                totalWeight += weight;\n            }\n        }\n        \n        if (totalWeight > 0.0f)\n        {\n            currentPitch = smoothedPitch / totalWeight;\n        }\n    }\n}\n\nfloat PitchCorrectionEngine::interpolateValue(float current, float target, float factor)\n{\n    factor = juce::jlimit(0.0f, 1.0f, factor);\n    return current + (target - current) * factor;\n}\n\nvoid PitchCorrectionEngine::applyHannWindow(float* buffer, int numSamples)\n{\n    for (int i = 0; i < numSamples; ++i)\n    {\n        float windowValue = 0.5f * (1.0f - std::cos(2.0f * juce::MathConstants<float>::pi * i / (numSamples - 1)));\n        buffer[i] *= windowValue;\n    }\n}\n\nvoid PitchCorrectionEngine::applyBlackmanWindow(float* buffer, int numSamples)\n{\n    const float a0 = 0.42f;\n    const float a1 = 0.5f;\n    const float a2 = 0.08f;\n    \n    for (int i = 0; i < numSamples; ++i)\n    {\n        float phase = 2.0f * juce::MathConstants<float>::pi * i / (numSamples - 1);\n        float windowValue = a0 - a1 * std::cos(phase) + a2 * std::cos(2.0f * phase);\n        buffer[i] *= windowValue;\n    }\n}\n","size_bytes":18261},"Source/PluginEditor.cpp":{"content":"#include \"PluginEditor.h\"\n#include \"Utils.h\"\n\nAutoTuneAudioProcessorEditor::AutoTuneAudioProcessorEditor(AutoTuneAudioProcessor& p)\n    : AudioProcessorEditor(p), \n      audioProcessor(p),\n      pitchHistory(pitchHistorySize, 0.0f)\n{\n    // Set custom look and feel\n    setLookAndFeel(&lookAndFeel);\n    \n    // Setup all controls\n    setupControls();\n    \n    // Set size\n    setSize(800, 600);\n    \n    // Start timer for real-time updates\n    startTimerHz(30); // 30 FPS\n    \n    // Initial layout\n    setupLayout();\n}\n\nAutoTuneAudioProcessorEditor::~AutoTuneAudioProcessorEditor()\n{\n    setLookAndFeel(nullptr);\n    stopTimer();\n}\n\nvoid AutoTuneAudioProcessorEditor::setupControls()\n{\n    // Speed Slider\n    speedSlider.setSliderStyle(juce::Slider::RotaryHorizontalVerticalDrag);\n    speedSlider.setTextBoxStyle(juce::Slider::TextBoxBelow, false, 80, 20);\n    speedSlider.setRange(0.0, 100.0, 0.1);\n    speedSlider.setValue(50.0);\n    speedSlider.setSkewFactor(0.5); // Make lower values more accessible\n    addAndMakeVisible(speedSlider);\n    \n    speedLabel.setText(\"Speed\", juce::dontSendNotification);\n    speedLabel.setJustificationType(juce::Justification::centred);\n    speedLabel.setColour(juce::Label::textColourId, juce::Colours::white);\n    addAndMakeVisible(speedLabel);\n    \n    speedAttachment = std::make_unique<juce::AudioProcessorValueTreeState::SliderAttachment>(\n        audioProcessor.getValueTreeState(), Parameters::SPEED_ID, speedSlider);\n    \n    // Amount Slider\n    amountSlider.setSliderStyle(juce::Slider::RotaryHorizontalVerticalDrag);\n    amountSlider.setTextBoxStyle(juce::Slider::TextBoxBelow, false, 80, 20);\n    amountSlider.setRange(0.0, 100.0, 0.1);\n    amountSlider.setValue(50.0);\n    addAndMakeVisible(amountSlider);\n    \n    amountLabel.setText(\"Amount\", juce::dontSendNotification);\n    amountLabel.setJustificationType(juce::Justification::centred);\n    amountLabel.setColour(juce::Label::textColourId, juce::Colours::white);\n    addAndMakeVisible(amountLabel);\n    \n    amountAttachment = std::make_unique<juce::AudioProcessorValueTreeState::SliderAttachment>(\n        audioProcessor.getValueTreeState(), Parameters::AMOUNT_ID, amountSlider);\n    \n    // Mode Selector\n    modeSelector.addItem(\"Classic\", 1);\n    modeSelector.addItem(\"Hard\", 2);\n    modeSelector.addItem(\"AI\", 3);\n    modeSelector.setSelectedId(1);\n    addAndMakeVisible(modeSelector);\n    \n    modeLabel.setText(\"Mode\", juce::dontSendNotification);\n    modeLabel.setJustificationType(juce::Justification::centred);\n    modeLabel.setColour(juce::Label::textColourId, juce::Colours::white);\n    addAndMakeVisible(modeLabel);\n    \n    modeAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(\n        audioProcessor.getValueTreeState(), Parameters::MODE_ID, modeSelector);\n    \n    // Key Selector\n    const char* keyNames[] = {\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"};\n    for (int i = 0; i < 12; ++i)\n    {\n        keySelector.addItem(keyNames[i], i + 1);\n    }\n    keySelector.setSelectedId(1); // C\n    addAndMakeVisible(keySelector);\n    \n    keyLabel.setText(\"Key\", juce::dontSendNotification);\n    keyLabel.setJustificationType(juce::Justification::centred);\n    keyLabel.setColour(juce::Label::textColourId, juce::Colours::white);\n    addAndMakeVisible(keyLabel);\n    \n    keyAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(\n        audioProcessor.getValueTreeState(), Parameters::KEY_ID, keySelector);\n    \n    // Scale Selector\n    scaleSelector.addItem(\"Major\", 1);\n    scaleSelector.addItem(\"Minor\", 2);\n    scaleSelector.addItem(\"Chromatic\", 3);\n    scaleSelector.setSelectedId(1); // Major\n    addAndMakeVisible(scaleSelector);\n    \n    scaleLabel.setText(\"Scale\", juce::dontSendNotification);\n    scaleLabel.setJustificationType(juce::Justification::centred);\n    scaleLabel.setColour(juce::Label::textColourId, juce::Colours::white);\n    addAndMakeVisible(scaleLabel);\n    \n    scaleAttachment = std::make_unique<juce::AudioProcessorValueTreeState::ComboBoxAttachment>(\n        audioProcessor.getValueTreeState(), Parameters::SCALE_ID, scaleSelector);\n    \n    // Preset Controls\n    savePresetButton.setButtonText(\"Save\");\n    savePresetButton.addListener(this);\n    addAndMakeVisible(savePresetButton);\n    \n    loadPresetButton.setButtonText(\"Load\");\n    loadPresetButton.addListener(this);\n    addAndMakeVisible(loadPresetButton);\n    \n    presetSelector.addItem(\"Default\", 1);\n    presetSelector.addItem(\"Vocal Classic\", 2);\n    presetSelector.addItem(\"Hard Tune\", 3);\n    presetSelector.addItem(\"AI Natural\", 4);\n    presetSelector.setSelectedId(1);\n    addAndMakeVisible(presetSelector);\n    \n    updatePresetList();\n}\n\nvoid AutoTuneAudioProcessorEditor::setupLayout()\n{\n    auto bounds = getLocalBounds();\n    \n    // Define layout areas\n    headerArea = bounds.removeFromTop(80);\n    presetArea = bounds.removeFromBottom(60);\n    controlsArea = bounds;\n}\n\nvoid AutoTuneAudioProcessorEditor::paint(juce::Graphics& g)\n{\n    // Background gradient\n    juce::ColourGradient gradient(\n        juce::Colour(0xff1e1e2e), 0.0f, 0.0f,\n        juce::Colour(0xff181825), 0.0f, static_cast<float>(getHeight()),\n        false\n    );\n    g.setGradientFill(gradient);\n    g.fillAll();\n    \n    // Draw sections\n    drawHeader(g, headerArea);\n    drawControls(g, controlsArea);\n    drawPresetSection(g, presetArea);\n}\n\nvoid AutoTuneAudioProcessorEditor::drawHeader(juce::Graphics& g, const juce::Rectangle<int>& area)\n{\n    // Header background\n    g.setColour(juce::Colour(0xff2d2d44));\n    g.fillRoundedRectangle(area.toFloat(), 8.0f);\n    \n    // Title\n    g.setColour(juce::Colours::white);\n    g.setFont(juce::Font(\"Arial\", 28.0f, juce::Font::bold));\n    g.drawText(\"ProAutoTune\", area.reduced(20), juce::Justification::centredLeft);\n    \n    // Version info\n    g.setFont(juce::Font(\"Arial\", 12.0f, juce::Font::plain));\n    g.setColour(juce::Colour(0xffb8b8c8));\n    g.drawText(\"v1.0\", area.reduced(20), juce::Justification::centredRight);\n    \n    // Draw level meters in header\n    auto meterArea = area.reduced(20).removeFromRight(200).reduced(10);\n    drawLevelMeters(g, meterArea);\n}\n\nvoid AutoTuneAudioProcessorEditor::drawControls(juce::Graphics& g, const juce::Rectangle<int>& area)\n{\n    auto bounds = area.reduced(20);\n    \n    // Main controls area\n    auto mainControlsArea = bounds.removeFromTop(bounds.getHeight() * 0.6f);\n    auto pitchDisplayArea = bounds;\n    \n    // Draw main controls background\n    g.setColour(juce::Colour(0xff2a2a3a));\n    g.fillRoundedRectangle(mainControlsArea.toFloat(), 8.0f);\n    \n    // Draw pitch display\n    drawPitchDisplay(g, pitchDisplayArea);\n}\n\nvoid AutoTuneAudioProcessorEditor::drawPresetSection(juce::Graphics& g, const juce::Rectangle<int>& area)\n{\n    // Preset section background\n    g.setColour(juce::Colour(0xff2d2d44));\n    g.fillRoundedRectangle(area.toFloat(), 8.0f);\n    \n    // Preset label\n    g.setColour(juce::Colours::white);\n    g.setFont(juce::Font(\"Arial\", 14.0f, juce::Font::plain));\n    g.drawText(\"Presets\", area.reduced(20, 10), juce::Justification::centredLeft);\n}\n\nvoid AutoTuneAudioProcessorEditor::drawPitchDisplay(juce::Graphics& g, const juce::Rectangle<int>& area)\n{\n    if (area.getWidth() < 10 || area.getHeight() < 10)\n        return;\n        \n    // Background\n    g.setColour(juce::Colour(0xff1a1a2e));\n    g.fillRoundedRectangle(area.toFloat(), 8.0f);\n    \n    // Border\n    g.setColour(juce::Colour(0xff3d3d5c));\n    g.drawRoundedRectangle(area.toFloat(), 8.0f, 2.0f);\n    \n    // Title\n    g.setColour(juce::Colours::white);\n    g.setFont(juce::Font(\"Arial\", 14.0f, juce::Font::plain));\n    g.drawText(\"Pitch Display\", area.reduced(10).removeFromTop(20), juce::Justification::centredLeft);\n    \n    // Draw pitch history\n    auto displayArea = area.reduced(20, 30);\n    if (displayArea.getWidth() > 0 && displayArea.getHeight() > 0)\n    {\n        juce::Path pitchPath;\n        bool firstPoint = true;\n        \n        for (int i = 0; i < pitchHistory.size(); ++i)\n        {\n            float x = displayArea.getX() + (float)i * displayArea.getWidth() / (float)pitchHistory.size();\n            float y = displayArea.getBottom() - (pitchHistory[i] * 0.5f + 0.5f) * displayArea.getHeight();\n            \n            if (firstPoint)\n            {\n                pitchPath.startNewSubPath(x, y);\n                firstPoint = false;\n            }\n            else\n            {\n                pitchPath.lineTo(x, y);\n            }\n        }\n        \n        // Draw pitch curve\n        g.setColour(juce::Colour(0xff4CAF50));\n        g.strokePath(pitchPath, juce::PathStrokeType(2.0f));\n        \n        // Draw center line (target pitch)\n        g.setColour(juce::Colour(0xff666666));\n        float centerY = displayArea.getCentreY();\n        g.drawLine(displayArea.getX(), centerY, displayArea.getRight(), centerY, 1.0f);\n    }\n}\n\nvoid AutoTuneAudioProcessorEditor::drawLevelMeters(juce::Graphics& g, const juce::Rectangle<int>& area)\n{\n    auto meterWidth = 20;\n    auto mutableArea = area;\n    auto inputMeterArea = mutableArea.removeFromLeft(meterWidth);\n    auto outputMeterArea = mutableArea.removeFromRight(meterWidth);\n    \n    // Input meter\n    g.setColour(juce::Colour(0xff333344));\n    g.fillRect(inputMeterArea);\n    \n    auto inputHeight = static_cast<int>(currentInputLevel * inputMeterArea.getHeight());\n    auto inputLevelArea = inputMeterArea.removeFromBottom(inputHeight);\n    \n    g.setColour(currentInputLevel > 0.8f ? juce::Colours::red : juce::Colours::green);\n    g.fillRect(inputLevelArea);\n    \n    // Output meter\n    g.setColour(juce::Colour(0xff333344));\n    g.fillRect(outputMeterArea);\n    \n    auto outputHeight = static_cast<int>(currentOutputLevel * outputMeterArea.getHeight());\n    auto outputLevelArea = outputMeterArea.removeFromBottom(outputHeight);\n    \n    g.setColour(currentOutputLevel > 0.8f ? juce::Colours::red : juce::Colours::blue);\n    g.fillRect(outputLevelArea);\n    \n    // Labels\n    g.setColour(juce::Colours::white);\n    g.setFont(10.0f);\n    g.drawText(\"IN\", inputMeterArea.withY(area.getBottom() + 5).withHeight(15), juce::Justification::centred);\n    g.drawText(\"OUT\", outputMeterArea.withY(area.getBottom() + 5).withHeight(15), juce::Justification::centred);\n}\n\nvoid AutoTuneAudioProcessorEditor::resized()\n{\n    setupLayout();\n    \n    auto bounds = getLocalBounds();\n    \n    // Skip header and preset areas for control layout\n    auto controlsBounds = bounds.reduced(40, 100);\n    controlsBounds.removeFromBottom(60);\n    \n    // Main rotary controls\n    auto rotaryArea = controlsBounds.removeFromTop(200);\n    auto sliderWidth = rotaryArea.getWidth() / 2 - 20;\n    \n    auto speedArea = rotaryArea.removeFromLeft(sliderWidth);\n    speedSlider.setBounds(speedArea.reduced(20, 10));\n    speedLabel.setBounds(speedArea.removeFromBottom(20));\n    \n    rotaryArea.removeFromLeft(40); // Spacing\n    \n    auto amountArea = rotaryArea;\n    amountSlider.setBounds(amountArea.reduced(20, 10));\n    amountLabel.setBounds(amountArea.removeFromBottom(20));\n    \n    // Selector controls\n    auto selectorArea = controlsBounds.removeFromTop(80);\n    auto selectorWidth = selectorArea.getWidth() / 3 - 20;\n    \n    auto modeArea = selectorArea.removeFromLeft(selectorWidth);\n    modeLabel.setBounds(modeArea.removeFromTop(20));\n    modeSelector.setBounds(modeArea.reduced(10));\n    \n    selectorArea.removeFromLeft(30); // Spacing\n    \n    auto keyArea = selectorArea.removeFromLeft(selectorWidth);\n    keyLabel.setBounds(keyArea.removeFromTop(20));\n    keySelector.setBounds(keyArea.reduced(10));\n    \n    selectorArea.removeFromLeft(30); // Spacing\n    \n    auto scaleArea = selectorArea;\n    scaleLabel.setBounds(scaleArea.removeFromTop(20));\n    scaleSelector.setBounds(scaleArea.reduced(10));\n    \n    // Preset controls at bottom\n    auto presetBounds = bounds.removeFromBottom(60).reduced(20, 10);\n    auto buttonWidth = 80;\n    \n    savePresetButton.setBounds(presetBounds.removeFromLeft(buttonWidth));\n    presetBounds.removeFromLeft(10);\n    loadPresetButton.setBounds(presetBounds.removeFromLeft(buttonWidth));\n    presetBounds.removeFromLeft(20);\n    presetSelector.setBounds(presetBounds);\n}\n\nvoid AutoTuneAudioProcessorEditor::timerCallback()\n{\n    // Update level meters (simplified - in real implementation would get from processor)\n    currentInputLevel = 0.3f + 0.2f * std::sin(juce::Time::getMillisecondCounter() * 0.01f);\n    currentOutputLevel = 0.25f + 0.15f * std::cos(juce::Time::getMillisecondCounter() * 0.008f);\n    \n    // Update pitch history (placeholder data)\n    for (int i = 0; i < pitchHistory.size() - 1; ++i)\n    {\n        pitchHistory[i] = pitchHistory[i + 1];\n    }\n    pitchHistory.back() = 0.1f * std::sin(juce::Time::getMillisecondCounter() * 0.005f);\n    \n    repaint();\n}\n\nvoid AutoTuneAudioProcessorEditor::buttonClicked(juce::Button* button)\n{\n    if (button == &savePresetButton)\n    {\n        // Save current settings as preset\n        audioProcessor.getPresetManager().savePreset(\"User Preset\");\n        updatePresetList();\n    }\n    else if (button == &loadPresetButton)\n    {\n        // Load selected preset\n        int selectedId = presetSelector.getSelectedId();\n        if (selectedId > 0)\n        {\n            audioProcessor.getPresetManager().loadPreset(selectedId - 1);\n        }\n    }\n}\n\nvoid AutoTuneAudioProcessorEditor::updatePresetList()\n{\n    // Update preset selector with available presets\n    presetSelector.clear();\n    \n    auto& presetManager = audioProcessor.getPresetManager();\n    auto presetNames = presetManager.getPresetNames();\n    \n    for (int i = 0; i < presetNames.size(); ++i)\n    {\n        presetSelector.addItem(presetNames[i], i + 1);\n    }\n    \n    if (presetSelector.getNumItems() > 0)\n        presetSelector.setSelectedId(1);\n}\n","size_bytes":13875},"Source/PluginProcessor.cpp":{"content":"#include \"PluginProcessor.h\"\n#include \"PluginEditor.h\"\n#include \"Utils.h\"\n\nAutoTuneAudioProcessor::AutoTuneAudioProcessor()\n    : AudioProcessor(BusesProperties()\n#if !JucePlugin_IsMidiEffect\n#if !JucePlugin_IsSynth\n        .withInput(\"Input\", juce::AudioChannelSet::stereo(), true)\n#endif\n        .withOutput(\"Output\", juce::AudioChannelSet::stereo(), true)\n#endif\n    ),\n    pluginParameters(),\n    parameters(*this, nullptr, juce::Identifier(\"AutoTuneParameters\"), pluginParameters.createParameterLayout()),\n    presetManager(parameters),\n    pitchEngine(),\n    modeSelector(),\n    aiModelLoader()\n{\n    // Add parameter listeners\n    parameters.addParameterListener(Parameters::SPEED_ID, this);\n    parameters.addParameterListener(Parameters::AMOUNT_ID, this);\n    parameters.addParameterListener(Parameters::MODE_ID, this);\n    parameters.addParameterListener(Parameters::KEY_ID, this);\n    parameters.addParameterListener(Parameters::SCALE_ID, this);\n\n    // Initialize FFT\n    fft = std::make_unique<juce::dsp::FFT>(fftOrder);\n    window = std::make_unique<juce::dsp::WindowingFunction<float>>(fftSize, juce::dsp::WindowingFunction<float>::hann);\n    frequencyData.allocate(fftSize, true);\n\n    // Initialize smoothed values\n    speedSmoothed.reset(44100.0, 0.05); // 50ms smoothing time\n    amountSmoothed.reset(44100.0, 0.05);\n}\n\nAutoTuneAudioProcessor::~AutoTuneAudioProcessor()\n{\n    parameters.removeParameterListener(Parameters::SPEED_ID, this);\n    parameters.removeParameterListener(Parameters::AMOUNT_ID, this);\n    parameters.removeParameterListener(Parameters::MODE_ID, this);\n    parameters.removeParameterListener(Parameters::KEY_ID, this);\n    parameters.removeParameterListener(Parameters::SCALE_ID, this);\n}\n\n// Methods moved to header as inline functions\n\nconst juce::String AutoTuneAudioProcessor::getProgramName(int index)\n{\n    juce::ignoreUnused(index);\n    return {};\n}\n\nvoid AutoTuneAudioProcessor::changeProgramName(int index, const juce::String& newName)\n{\n    juce::ignoreUnused(index, newName);\n}\n\nvoid AutoTuneAudioProcessor::prepareToPlay(double sampleRate, int samplesPerBlock)\n{\n    currentSampleRate = sampleRate;\n    currentBlockSize = samplesPerBlock;\n\n    // Prepare pitch correction engine\n    pitchEngine.prepare(sampleRate, samplesPerBlock);\n\n    // Initialize buffers\n    pitchBuffer.setSize(2, samplesPerBlock);\n    correctedBuffer.setSize(2, samplesPerBlock);\n    overlapBuffer.setSize(2, overlapSize);\n    fftBuffer.setSize(1, fftSize);\n\n    overlapBuffer.clear();\n    overlapPosition = 0;\n\n    // Initialize smoothed values\n    speedSmoothed.reset(sampleRate, 0.05);\n    amountSmoothed.reset(sampleRate, 0.05);\n    \n    speedSmoothed.setCurrentAndTargetValue(*parameters.getRawParameterValue(Parameters::SPEED_ID));\n    amountSmoothed.setCurrentAndTargetValue(*parameters.getRawParameterValue(Parameters::AMOUNT_ID));\n\n#ifdef USE_RUBBERBAND\n    // Initialize Rubber Band stretcher\n    rubberBand = std::make_unique<RubberBand::RubberBandStretcher>(\n        sampleRate, 2,\n        RubberBand::RubberBandStretcher::OptionProcessRealTime |\n        RubberBand::RubberBandStretcher::OptionPitchHighQuality\n    );\n#endif\n}\n\nvoid AutoTuneAudioProcessor::releaseResources()\n{\n    pitchBuffer.setSize(0, 0);\n    correctedBuffer.setSize(0, 0);\n    overlapBuffer.setSize(0, 0);\n    fftBuffer.setSize(0, 0);\n\n#ifdef USE_RUBBERBAND\n    rubberBand.reset();\n#endif\n}\n\n#ifndef JucePlugin_PreferredChannelConfigurations\nbool AutoTuneAudioProcessor::isBusesLayoutSupported(const BusesLayout& layouts) const\n{\n#if JucePlugin_IsMidiEffect\n    juce::ignoreUnused(layouts);\n    return true;\n#else\n    // This is the place where you check if the layout is supported.\n    if (layouts.getMainOutputChannelSet() != juce::AudioChannelSet::mono()\n        && layouts.getMainOutputChannelSet() != juce::AudioChannelSet::stereo())\n        return false;\n\n#if !JucePlugin_IsSynth\n    if (layouts.getMainOutputChannelSet() != layouts.getMainInputChannelSet())\n        return false;\n#endif\n\n    return true;\n#endif\n}\n#endif\n\nvoid AutoTuneAudioProcessor::processBlock(juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)\n{\n    juce::ignoreUnused(midiMessages);\n\n    juce::ScopedNoDenormals noDenormals;\n    auto totalNumInputChannels = getTotalNumInputChannels();\n    auto totalNumOutputChannels = getTotalNumOutputChannels();\n\n    // Clear any output channels that don't contain input data\n    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)\n        buffer.clear(i, 0, buffer.getNumSamples());\n\n    if (buffer.getNumSamples() == 0)\n        return;\n\n    // Update smoothed parameter values\n    speedSmoothed.setTargetValue(*parameters.getRawParameterValue(Parameters::SPEED_ID));\n    amountSmoothed.setTargetValue(*parameters.getRawParameterValue(Parameters::AMOUNT_ID));\n\n    // Get current mode\n    auto currentMode = static_cast<Parameters::Mode>(\n        static_cast<int>(*parameters.getRawParameterValue(Parameters::MODE_ID))\n    );\n\n    // Process based on selected mode\n    switch (currentMode)\n    {\n        case Parameters::Mode::Classic:\n            processClassicMode(buffer);\n            break;\n        case Parameters::Mode::Hard:\n            processHardMode(buffer);\n            break;\n        case Parameters::Mode::AI:\n            processAIMode(buffer);\n            break;\n    }\n}\n\nvoid AutoTuneAudioProcessor::processClassicMode(juce::AudioBuffer<float>& buffer)\n{\n    const int numSamples = buffer.getNumSamples();\n    const int numChannels = buffer.getNumChannels();\n\n    // Get parameter values\n    float speed = speedSmoothed.getNextValue();\n    float amount = amountSmoothed.getNextValue();\n    auto key = static_cast<Parameters::Key>(\n        static_cast<int>(*parameters.getRawParameterValue(Parameters::KEY_ID))\n    );\n    auto scale = static_cast<Parameters::Scale>(\n        static_cast<int>(*parameters.getRawParameterValue(Parameters::SCALE_ID))\n    );\n\n    // Process each channel\n    for (int channel = 0; channel < numChannels; ++channel)\n    {\n        auto* channelData = buffer.getWritePointer(channel);\n        \n        // Pitch detection and correction\n        std::vector<float> pitches(numSamples);\n        pitchEngine.detectPitch(channelData, numSamples, pitches.data());\n        \n        // Apply pitch correction\n        for (int sample = 0; sample < numSamples; ++sample)\n        {\n            float currentPitch = pitches[sample];\n            \n            if (currentPitch > 0.0f) // Valid pitch detected\n            {\n                // Convert to MIDI note number\n                float midiNote = Utils::frequencyToMidiNote(currentPitch);\n                \n                // Quantize to scale\n                float targetNote = Utils::quantizeToScale(midiNote, key, scale);\n                float targetFrequency = Utils::midiNoteToFrequency(targetNote);\n                \n                // Calculate correction amount\n                float correction = (targetFrequency - currentPitch) * amount;\n                \n                // Apply smooth correction with speed control\n                float smoothedCorrection = correction * speed * 0.1f; // Scale speed appropriately\n                \n                // Apply correction (simplified - real implementation would use pitch shifting)\n                channelData[sample] *= (1.0f + smoothedCorrection * 0.001f); // Very subtle effect for demo\n            }\n        }\n    }\n}\n\nvoid AutoTuneAudioProcessor::processHardMode(juce::AudioBuffer<float>& buffer)\n{\n    const int numSamples = buffer.getNumSamples();\n    const int numChannels = buffer.getNumChannels();\n\n    // Get parameter values\n    float speed = speedSmoothed.getNextValue();\n    float amount = amountSmoothed.getNextValue();\n    auto key = static_cast<Parameters::Key>(\n        static_cast<int>(*parameters.getRawParameterValue(Parameters::KEY_ID))\n    );\n    auto scale = static_cast<Parameters::Scale>(\n        static_cast<int>(*parameters.getRawParameterValue(Parameters::SCALE_ID))\n    );\n\n    // Hard mode applies immediate, aggressive correction\n    for (int channel = 0; channel < numChannels; ++channel)\n    {\n        auto* channelData = buffer.getWritePointer(channel);\n        \n        // Detect pitch\n        std::vector<float> pitches(numSamples);\n        pitchEngine.detectPitch(channelData, numSamples, pitches.data());\n        \n        // Apply hard correction\n        for (int sample = 0; sample < numSamples; ++sample)\n        {\n            float currentPitch = pitches[sample];\n            \n            if (currentPitch > 0.0f)\n            {\n                float midiNote = Utils::frequencyToMidiNote(currentPitch);\n                float targetNote = Utils::quantizeToScale(midiNote, key, scale);\n                float targetFrequency = Utils::midiNoteToFrequency(targetNote);\n                \n                // Hard correction - immediate snap to target\n                float correction = (targetFrequency - currentPitch) * amount;\n                float hardCorrection = correction * juce::jmin(speed * 10.0f, 1.0f); // Faster, harder correction\n                \n                // Apply more aggressive correction\n                channelData[sample] *= (1.0f + hardCorrection * 0.01f);\n            }\n        }\n    }\n}\n\nvoid AutoTuneAudioProcessor::processAIMode(juce::AudioBuffer<float>& buffer)\n{\n    const int numSamples = buffer.getNumSamples();\n    const int numChannels = buffer.getNumChannels();\n\n    // Get parameter values\n    float speed = speedSmoothed.getNextValue();\n    float amount = amountSmoothed.getNextValue();\n    auto key = static_cast<Parameters::Key>(\n        static_cast<int>(*parameters.getRawParameterValue(Parameters::KEY_ID))\n    );\n    auto scale = static_cast<Parameters::Scale>(\n        static_cast<int>(*parameters.getRawParameterValue(Parameters::SCALE_ID))\n    );\n\n    // AI-enhanced processing with CREPE/DDSP integration\n    for (int channel = 0; channel < numChannels; ++channel)\n    {\n        auto* channelData = buffer.getWritePointer(channel);\n        \n        if (aiModelLoader.areModelsLoaded())\n        {\n            // Use AI models for pitch detection and synthesis\n            auto pitchPrediction = aiModelLoader.predictPitch(channelData, numSamples, currentSampleRate);\n            \n            if (pitchPrediction.confidence > 0.3f) // Only process if confident\n            {\n                float currentPitch = pitchPrediction.frequency;\n                float midiNote = Utils::frequencyToMidiNote(currentPitch);\n                float targetNote = Utils::quantizeToScale(midiNote, key, scale);\n                float targetFrequency = Utils::midiNoteToFrequency(targetNote);\n                \n                // Create synthesis parameters for DDSP\n                AIModelLoader::SynthesisParams synthParams;\n                synthParams.fundamentalFreq = targetFrequency;\n                synthParams.harmonicAmplitudes = pitchPrediction.harmonics;\n                synthParams.loudness = amount * 0.01f;\n                \n                // Process with DDSP for natural-sounding correction\n                std::vector<float> tempBuffer(numSamples);\n                std::copy(channelData, channelData + numSamples, tempBuffer.begin());\n                \n                if (aiModelLoader.processWithDDSP(tempBuffer.data(), channelData, numSamples, synthParams))\n                {\n                    // Blend original and AI-processed audio based on speed parameter\n                    float blendFactor = speed * 0.01f;\n                    for (int i = 0; i < numSamples; ++i)\n                    {\n                        channelData[i] = tempBuffer[i] * (1.0f - blendFactor) + channelData[i] * blendFactor;\n                    }\n                }\n            }\n        }\n        else\n        {\n            // Fallback to advanced pitch detection without AI models\n            std::vector<float> pitches(numSamples);\n            pitchEngine.detectPitchAdvanced(channelData, numSamples, pitches.data());\n            \n            // AI-style correction with formant preservation\n            for (int sample = 0; sample < numSamples; ++sample)\n            {\n                float currentPitch = pitches[sample];\n                \n                if (currentPitch > 0.0f)\n                {\n                    float midiNote = Utils::frequencyToMidiNote(currentPitch);\n                    float targetNote = Utils::quantizeToScale(midiNote, key, scale);\n                    float targetFrequency = Utils::midiNoteToFrequency(targetNote);\n                    \n                    // AI-style smooth correction with natural timing\n                    float pitchDiff = std::abs(targetFrequency - currentPitch);\n                    float aiSpeed = speed * (1.0f - std::exp(-pitchDiff * 0.1f)); // Adaptive speed\n                    float correction = (targetFrequency - currentPitch) * amount * aiSpeed * 0.01f;\n                    \n                    // Apply with formant considerations (simplified)\n                    channelData[sample] *= (1.0f + correction * 0.005f);\n                }\n            }\n        }\n    }\n\n#ifdef USE_RUBBERBAND\n    // Use Rubber Band for high-quality time/pitch manipulation in AI mode\n    if (rubberBand)\n    {\n        // Configure rubber band for pitch shifting\n        float pitchShift = amount * 0.1f; // Convert amount to pitch shift ratio\n        rubberBand->setPitchScale(1.0f + pitchShift);\n        \n        // Process through rubber band (simplified integration)\n        // Real implementation would handle proper buffering and processing\n    }\n#endif\n}\n\nvoid AutoTuneAudioProcessor::parameterChanged(const juce::String& parameterID, float newValue)\n{\n    if (parameterID == Parameters::SPEED_ID)\n    {\n        speedSmoothed.setTargetValue(newValue);\n    }\n    else if (parameterID == Parameters::AMOUNT_ID)\n    {\n        amountSmoothed.setTargetValue(newValue);\n    }\n    else if (parameterID == Parameters::MODE_ID)\n    {\n        // Mode changed - could trigger additional setup\n        auto newMode = static_cast<Parameters::Mode>(static_cast<int>(newValue));\n        modeSelector.setCurrentMode(newMode);\n    }\n}\n\njuce::AudioProcessorEditor* AutoTuneAudioProcessor::createEditor()\n{\n    return new AutoTuneAudioProcessorEditor(*this);\n}\n\nvoid AutoTuneAudioProcessor::getStateInformation(juce::MemoryBlock& destData)\n{\n    auto state = parameters.copyState();\n    std::unique_ptr<juce::XmlElement> xml(state.createXml());\n    copyXmlToBinary(*xml, destData);\n}\n\nvoid AutoTuneAudioProcessor::setStateInformation(const void* data, int sizeInBytes)\n{\n    std::unique_ptr<juce::XmlElement> xmlState(getXmlFromBinary(data, sizeInBytes));\n    \n    if (xmlState.get() != nullptr)\n    {\n        if (xmlState->hasTagName(parameters.state.getType()))\n        {\n            parameters.replaceState(juce::ValueTree::fromXml(*xmlState));\n        }\n    }\n}\n\n// This creates new instances of the plugin\njuce::AudioProcessor* JUCE_CALLTYPE createPluginFilter()\n{\n    return static_cast<juce::AudioProcessor*>(new AutoTuneAudioProcessor());\n}\n","size_bytes":15043},"Source/PresetManager.cpp":{"content":"#include \"PresetManager.h\"\n#include \"Parameters.h\"\n\nconst juce::String PresetManager::presetFileExtension = \".xml\";\nconst juce::String PresetManager::presetFileName = \"ProAutoTunePresets.xml\";\n\nPresetManager::PresetManager(juce::AudioProcessorValueTreeState& params)\n    : parameters(params), currentPresetIndex(-1)\n{\n    loadFactoryPresets();\n    loadPresetsFromFile();\n}\n\nPresetManager::~PresetManager()\n{\n    savePresetsToFile();\n}\n\nvoid PresetManager::savePreset(const juce::String& name, const juce::String& description)\n{\n    if (name.isEmpty())\n        return;\n    \n    // Check if preset with this name already exists\n    int existingIndex = -1;\n    for (int i = 0; i < static_cast<int>(presets.size()); ++i)\n    {\n        if (presets[i].name == name)\n        {\n            existingIndex = i;\n            break;\n        }\n    }\n    \n    Preset newPreset = createPresetFromCurrentState(name, description);\n    \n    if (existingIndex >= 0)\n    {\n        // Replace existing preset\n        presets[existingIndex] = newPreset;\n        currentPresetIndex = existingIndex;\n    }\n    else\n    {\n        // Add new preset\n        presets.push_back(newPreset);\n        currentPresetIndex = static_cast<int>(presets.size()) - 1;\n    }\n    \n    savePresetsToFile();\n    \n    if (onPresetSaved)\n        onPresetSaved(name);\n}\n\nbool PresetManager::loadPreset(int index)\n{\n    if (!isValidPresetIndex(index))\n        return false;\n    \n    const auto& preset = presets[index];\n    applyPresetToParameters(preset);\n    currentPresetIndex = index;\n    \n    if (onPresetChanged)\n        onPresetChanged();\n    \n    return true;\n}\n\nbool PresetManager::loadPreset(const juce::String& name)\n{\n    for (int i = 0; i < static_cast<int>(presets.size()); ++i)\n    {\n        if (presets[i].name == name)\n        {\n            return loadPreset(i);\n        }\n    }\n    return false;\n}\n\nvoid PresetManager::deletePreset(int index)\n{\n    if (!isValidPresetIndex(index))\n        return;\n    \n    juce::String deletedName = presets[index].name;\n    presets.erase(presets.begin() + index);\n    \n    if (currentPresetIndex == index)\n    {\n        currentPresetIndex = -1;\n    }\n    else if (currentPresetIndex > index)\n    {\n        currentPresetIndex--;\n    }\n    \n    savePresetsToFile();\n    \n    if (onPresetDeleted)\n        onPresetDeleted(deletedName);\n}\n\nvoid PresetManager::deletePreset(const juce::String& name)\n{\n    for (int i = 0; i < static_cast<int>(presets.size()); ++i)\n    {\n        if (presets[i].name == name)\n        {\n            deletePreset(i);\n            break;\n        }\n    }\n}\n\nvoid PresetManager::loadFactoryPresets()\n{\n    presets.clear();\n    \n    // Add factory presets with professional settings\n    addFactoryPreset(\"Default\", 50.0f, 50.0f, 0, 0, 0, \"Balanced correction for most vocals\");\n    addFactoryPreset(\"Vocal Classic\", 30.0f, 70.0f, 0, 0, 0, \"Smooth, natural vocal correction\");\n    addFactoryPreset(\"Hard Tune\", 90.0f, 85.0f, 1, 0, 0, \"Aggressive T-Pain style effect\");\n    addFactoryPreset(\"AI Natural\", 25.0f, 60.0f, 2, 0, 0, \"AI-powered natural correction\");\n    addFactoryPreset(\"Pop Vocal\", 40.0f, 75.0f, 0, 0, 0, \"Perfect for pop vocals\");\n    addFactoryPreset(\"Rap Vocal\", 80.0f, 90.0f, 1, 0, 2, \"Hard correction for rap vocals\");\n    addFactoryPreset(\"Choir\", 20.0f, 40.0f, 2, 0, 0, \"Gentle correction for choir vocals\");\n    addFactoryPreset(\"Robot Voice\", 100.0f, 100.0f, 1, 0, 2, \"Full robotic effect\");\n    addFactoryPreset(\"Subtle Fix\", 15.0f, 30.0f, 0, 0, 0, \"Very gentle pitch correction\");\n    addFactoryPreset(\"Major Scale Fix\", 60.0f, 80.0f, 0, 0, 0, \"Strong correction to major scale\");\n    addFactoryPreset(\"Minor Blues\", 45.0f, 65.0f, 0, 9, 1, \"A minor scale correction\");\n    addFactoryPreset(\"Chromatic\", 70.0f, 50.0f, 0, 0, 2, \"Chromatic scale correction\");\n}\n\nvoid PresetManager::resetToDefaults()\n{\n    parameters.getParameter(Parameters::SPEED_ID)->setValueNotifyingHost(\n        parameters.getParameterRange(Parameters::SPEED_ID).convertTo0to1(Parameters::SPEED_DEFAULT));\n    parameters.getParameter(Parameters::AMOUNT_ID)->setValueNotifyingHost(\n        parameters.getParameterRange(Parameters::AMOUNT_ID).convertTo0to1(Parameters::AMOUNT_DEFAULT));\n    parameters.getParameter(Parameters::MODE_ID)->setValueNotifyingHost(\n        static_cast<float>(Parameters::MODE_DEFAULT) / 2.0f);\n    parameters.getParameter(Parameters::KEY_ID)->setValueNotifyingHost(\n        static_cast<float>(Parameters::KEY_DEFAULT) / 11.0f);\n    parameters.getParameter(Parameters::SCALE_ID)->setValueNotifyingHost(\n        static_cast<float>(Parameters::SCALE_DEFAULT) / 2.0f);\n    \n    currentPresetIndex = -1;\n    \n    if (onPresetChanged)\n        onPresetChanged();\n}\n\nconst PresetManager::Preset& PresetManager::getPreset(int index) const\n{\n    static Preset emptyPreset;\n    \n    if (isValidPresetIndex(index))\n        return presets[index];\n    \n    return emptyPreset;\n}\n\njuce::StringArray PresetManager::getPresetNames() const\n{\n    juce::StringArray names;\n    for (const auto& preset : presets)\n    {\n        names.add(preset.name);\n    }\n    return names;\n}\n\nvoid PresetManager::savePresetsToFile()\n{\n    auto presetFile = getPresetFile();\n    \n    juce::XmlElement root(\"ProAutoTunePresets\");\n    root.setAttribute(\"version\", \"1.0\");\n    root.setAttribute(\"count\", static_cast<int>(presets.size()));\n    \n    for (const auto& preset : presets)\n    {\n        auto presetElement = root.createNewChildElement(\"Preset\");\n        writePresetToXml(preset, *presetElement);\n    }\n    \n    if (!root.writeTo(presetFile))\n    {\n        DBG(\"Failed to save presets to file: \" + presetFile.getFullPathName());\n    }\n}\n\nvoid PresetManager::loadPresetsFromFile()\n{\n    auto presetFile = getPresetFile();\n    \n    if (!presetFile.existsAsFile())\n        return;\n    \n    auto xml = juce::XmlDocument::parse(presetFile);\n    if (xml == nullptr)\n        return;\n    \n    if (!xml->hasTagName(\"ProAutoTunePresets\"))\n        return;\n    \n    // Clear existing user presets but keep factory presets\n    std::vector<Preset> factoryPresets;\n    for (const auto& preset : presets)\n    {\n        // Assume factory presets are the first ones loaded\n        if (preset.description.contains(\"factory\") || \n            preset.name == \"Default\" || preset.name == \"Vocal Classic\" ||\n            preset.name == \"Hard Tune\" || preset.name == \"AI Natural\")\n        {\n            factoryPresets.push_back(preset);\n        }\n    }\n    \n    presets = factoryPresets;\n    \n    // Load user presets\n    for (auto* presetElement : xml->getChildIterator())\n    {\n        if (presetElement->hasTagName(\"Preset\"))\n        {\n            Preset preset;\n            if (readPresetFromXml(*presetElement, preset))\n            {\n                // Only add if not a factory preset\n                bool isFactory = false;\n                for (const auto& factoryPreset : factoryPresets)\n                {\n                    if (factoryPreset.name == preset.name)\n                    {\n                        isFactory = true;\n                        break;\n                    }\n                }\n                \n                if (!isFactory)\n                {\n                    presets.push_back(preset);\n                }\n            }\n        }\n    }\n}\n\njuce::File PresetManager::getPresetDirectory() const\n{\n    auto userDocsDir = juce::File::getSpecialLocation(juce::File::userDocumentsDirectory);\n    auto presetDir = userDocsDir.getChildFile(\"ProAutoTune\").getChildFile(\"Presets\");\n    \n    if (!presetDir.exists())\n        presetDir.createDirectory();\n    \n    return presetDir;\n}\n\njuce::File PresetManager::getPresetFile() const\n{\n    return getPresetDirectory().getChildFile(presetFileName);\n}\n\nbool PresetManager::exportPreset(int index, const juce::File& file)\n{\n    if (!isValidPresetIndex(index))\n        return false;\n    \n    const auto& preset = presets[index];\n    \n    juce::XmlElement root(\"ProAutoTunePreset\");\n    root.setAttribute(\"version\", \"1.0\");\n    \n    auto presetElement = root.createNewChildElement(\"Preset\");\n    writePresetToXml(preset, *presetElement);\n    \n    return root.writeTo(file);\n}\n\nbool PresetManager::importPreset(const juce::File& file)\n{\n    if (!file.existsAsFile())\n        return false;\n    \n    auto xml = juce::XmlDocument::parse(file);\n    if (xml == nullptr || !xml->hasTagName(\"ProAutoTunePreset\"))\n        return false;\n    \n    auto presetElement = xml->getChildByName(\"Preset\");\n    if (presetElement == nullptr)\n        return false;\n    \n    Preset preset;\n    if (readPresetFromXml(*presetElement, preset))\n    {\n        // Check for name conflicts\n        juce::String originalName = preset.name;\n        int counter = 1;\n        while (presetExists(preset.name))\n        {\n            preset.name = originalName + \" (\" + juce::String(counter++) + \")\";\n        }\n        \n        presets.push_back(preset);\n        savePresetsToFile();\n        return true;\n    }\n    \n    return false;\n}\n\nbool PresetManager::exportAllPresets(const juce::File& file)\n{\n    juce::XmlElement root(\"ProAutoTunePresets\");\n    root.setAttribute(\"version\", \"1.0\");\n    root.setAttribute(\"count\", static_cast<int>(presets.size()));\n    \n    for (const auto& preset : presets)\n    {\n        auto presetElement = root.createNewChildElement(\"Preset\");\n        writePresetToXml(preset, *presetElement);\n    }\n    \n    return root.writeTo(file);\n}\n\nbool PresetManager::importPresetsFromFile(const juce::File& file)\n{\n    if (!file.existsAsFile())\n        return false;\n    \n    auto xml = juce::XmlDocument::parse(file);\n    if (xml == nullptr || !xml->hasTagName(\"ProAutoTunePresets\"))\n        return false;\n    \n    int importedCount = 0;\n    \n    for (auto* presetElement : xml->getChildIterator())\n    {\n        if (presetElement->hasTagName(\"Preset\"))\n        {\n            Preset preset;\n            if (readPresetFromXml(*presetElement, preset))\n            {\n                // Handle name conflicts\n                juce::String originalName = preset.name;\n                int counter = 1;\n                while (presetExists(preset.name))\n                {\n                    preset.name = originalName + \" (\" + juce::String(counter++) + \")\";\n                }\n                \n                presets.push_back(preset);\n                importedCount++;\n            }\n        }\n    }\n    \n    if (importedCount > 0)\n    {\n        savePresetsToFile();\n        return true;\n    }\n    \n    return false;\n}\n\nbool PresetManager::isValidPresetIndex(int index) const\n{\n    return index >= 0 && index < static_cast<int>(presets.size());\n}\n\nbool PresetManager::presetExists(const juce::String& name) const\n{\n    for (const auto& preset : presets)\n    {\n        if (preset.name == name)\n            return true;\n    }\n    return false;\n}\n\nPresetManager::Preset PresetManager::createPresetFromCurrentState(const juce::String& name, const juce::String& description)\n{\n    Preset preset;\n    preset.name = name;\n    preset.description = description;\n    preset.dateCreated = juce::Time::getCurrentTime();\n    \n    preset.speed = *parameters.getRawParameterValue(Parameters::SPEED_ID);\n    preset.amount = *parameters.getRawParameterValue(Parameters::AMOUNT_ID);\n    preset.mode = static_cast<int>(*parameters.getRawParameterValue(Parameters::MODE_ID));\n    preset.key = static_cast<int>(*parameters.getRawParameterValue(Parameters::KEY_ID));\n    preset.scale = static_cast<int>(*parameters.getRawParameterValue(Parameters::SCALE_ID));\n    \n    return preset;\n}\n\nvoid PresetManager::applyPresetToParameters(const Preset& preset)\n{\n    auto speedRange = parameters.getParameterRange(Parameters::SPEED_ID);\n    auto amountRange = parameters.getParameterRange(Parameters::AMOUNT_ID);\n    \n    parameters.getParameter(Parameters::SPEED_ID)->setValueNotifyingHost(\n        speedRange.convertTo0to1(preset.speed));\n    parameters.getParameter(Parameters::AMOUNT_ID)->setValueNotifyingHost(\n        amountRange.convertTo0to1(preset.amount));\n    parameters.getParameter(Parameters::MODE_ID)->setValueNotifyingHost(\n        static_cast<float>(preset.mode) / 2.0f);\n    parameters.getParameter(Parameters::KEY_ID)->setValueNotifyingHost(\n        static_cast<float>(preset.key) / 11.0f);\n    parameters.getParameter(Parameters::SCALE_ID)->setValueNotifyingHost(\n        static_cast<float>(preset.scale) / 2.0f);\n}\n\njuce::ValueTree PresetManager::presetToValueTree(const Preset& preset)\n{\n    juce::ValueTree tree(\"Preset\");\n    tree.setProperty(\"name\", preset.name, nullptr);\n    tree.setProperty(\"description\", preset.description, nullptr);\n    tree.setProperty(\"speed\", preset.speed, nullptr);\n    tree.setProperty(\"amount\", preset.amount, nullptr);\n    tree.setProperty(\"mode\", preset.mode, nullptr);\n    tree.setProperty(\"key\", preset.key, nullptr);\n    tree.setProperty(\"scale\", preset.scale, nullptr);\n    tree.setProperty(\"dateCreated\", preset.dateCreated.toISO8601(true), nullptr);\n    \n    return tree;\n}\n\nPresetManager::Preset PresetManager::valueTreeToPreset(const juce::ValueTree& tree)\n{\n    Preset preset;\n    preset.name = tree.getProperty(\"name\", \"Untitled\");\n    preset.description = tree.getProperty(\"description\", \"\");\n    preset.speed = tree.getProperty(\"speed\", 50.0f);\n    preset.amount = tree.getProperty(\"amount\", 50.0f);\n    preset.mode = tree.getProperty(\"mode\", 0);\n    preset.key = tree.getProperty(\"key\", 0);\n    preset.scale = tree.getProperty(\"scale\", 0);\n    \n    juce::String dateString = tree.getProperty(\"dateCreated\", \"\");\n    if (dateString.isNotEmpty())\n    {\n        preset.dateCreated = juce::Time::fromISO8601(dateString);\n    }\n    else\n    {\n        preset.dateCreated = juce::Time::getCurrentTime();\n    }\n    \n    return preset;\n}\n\nvoid PresetManager::addFactoryPreset(const juce::String& name, float speed, float amount, \n                                    int mode, int key, int scale, const juce::String& description)\n{\n    Preset preset(name, speed, amount, mode, key, scale, description);\n    presets.push_back(preset);\n}\n\nbool PresetManager::writePresetToXml(const Preset& preset, juce::XmlElement& xml)\n{\n    xml.setAttribute(\"name\", preset.name);\n    xml.setAttribute(\"description\", preset.description);\n    xml.setAttribute(\"speed\", preset.speed);\n    xml.setAttribute(\"amount\", preset.amount);\n    xml.setAttribute(\"mode\", preset.mode);\n    xml.setAttribute(\"key\", preset.key);\n    xml.setAttribute(\"scale\", preset.scale);\n    xml.setAttribute(\"dateCreated\", preset.dateCreated.toISO8601(true));\n    \n    return true;\n}\n\nbool PresetManager::readPresetFromXml(const juce::XmlElement& xml, Preset& preset)\n{\n    if (!xml.hasAttribute(\"name\"))\n        return false;\n    \n    preset.name = xml.getStringAttribute(\"name\");\n    preset.description = xml.getStringAttribute(\"description\");\n    preset.speed = static_cast<float>(xml.getDoubleAttribute(\"speed\", 50.0));\n    preset.amount = static_cast<float>(xml.getDoubleAttribute(\"amount\", 50.0));\n    preset.mode = xml.getIntAttribute(\"mode\", 0);\n    preset.key = xml.getIntAttribute(\"key\", 0);\n    preset.scale = xml.getIntAttribute(\"scale\", 0);\n    \n    juce::String dateString = xml.getStringAttribute(\"dateCreated\");\n    if (dateString.isNotEmpty())\n    {\n        preset.dateCreated = juce::Time::fromISO8601(dateString);\n    }\n    else\n    {\n        preset.dateCreated = juce::Time::getCurrentTime();\n    }\n    \n    return true;\n}\n","size_bytes":15354},"Source/Utils.cpp":{"content":"#include \"Utils.h\"\n#include <algorithm>\n#include <numeric>\n\n// Initialize static lookup tables\nstd::vector<float> Utils::sinLookupTable(LOOKUP_TABLE_SIZE);\nstd::vector<float> Utils::cosLookupTable(LOOKUP_TABLE_SIZE);\n\nfloat Utils::frequencyToMidiNote(float frequency)\n{\n    if (frequency <= 0.0f)\n        return 0.0f;\n    \n    return MIDI_A4 + 12.0f * std::log2(frequency / CONCERT_A_FREQ);\n}\n\nfloat Utils::midiNoteToFrequency(float midiNote)\n{\n    return CONCERT_A_FREQ * std::pow(2.0f, (midiNote - MIDI_A4) / 12.0f);\n}\n\nfloat Utils::quantizeToScale(float midiNote, Parameters::Key key, Parameters::Scale scale)\n{\n    if (midiNote <= 0.0f)\n        return midiNote;\n    \n    // Get the scale notes for the specified scale\n    const auto& scaleNotes = Parameters::getScaleNotes(scale);\n    int keyOffset = static_cast<int>(key);\n    \n    // Find the nearest scale note\n    int quantizedNote = findNearestScaleNote(midiNote, scaleNotes, keyOffset);\n    \n    return static_cast<float>(quantizedNote);\n}\n\nint Utils::findNearestScaleNote(float midiNote, const std::vector<int>& scaleNotes, int keyOffset)\n{\n    int noteInt = static_cast<int>(std::round(midiNote));\n    int octave = noteInt / 12;\n    int noteInOctave = noteInt % 12;\n    \n    // Handle negative notes\n    if (noteInOctave < 0)\n    {\n        noteInOctave += 12;\n        octave--;\n    }\n    \n    // Find the closest note in the scale\n    int closestNote = 0;\n    float minDistance = 12.0f;\n    \n    for (int scaleNote : scaleNotes)\n    {\n        int scaledNote = (scaleNote + keyOffset) % 12;\n        \n        // Check distance in both directions (considering wrap-around)\n        float distance1 = std::abs(noteInOctave - scaledNote);\n        float distance2 = 12.0f - distance1;\n        float distance = std::min(distance1, distance2);\n        \n        if (distance < minDistance)\n        {\n            minDistance = distance;\n            closestNote = scaledNote;\n        }\n    }\n    \n    return octave * 12 + closestNote;\n}\n\nfloat Utils::linearToDecibels(float linearValue)\n{\n    if (linearValue <= 0.0f)\n        return -100.0f; // Effective negative infinity\n    \n    return 20.0f * std::log10(linearValue);\n}\n\nfloat Utils::decibelsToLinear(float decibels)\n{\n    return std::pow(10.0f, decibels / 20.0f);\n}\n\nfloat Utils::rmsToDecibels(float rmsValue)\n{\n    return linearToDecibels(rmsValue);\n}\n\nfloat Utils::linearInterpolation(float x1, float y1, float x2, float y2, float x)\n{\n    if (std::abs(x2 - x1) < 1e-6f)\n        return y1;\n    \n    float t = (x - x1) / (x2 - x1);\n    return y1 + t * (y2 - y1);\n}\n\nfloat Utils::cubicInterpolation(float y0, float y1, float y2, float y3, float x)\n{\n    float a = y3 - y2 - y0 + y1;\n    float b = y0 - y1 - a;\n    float c = y2 - y0;\n    float d = y1;\n    \n    return a * x * x * x + b * x * x + c * x + d;\n}\n\nfloat Utils::hermiteInterpolation(float y0, float y1, float y2, float y3, float x)\n{\n    float c0 = y1;\n    float c1 = 0.5f * (y2 - y0);\n    float c2 = y0 - 2.5f * y1 + 2.0f * y2 - 0.5f * y3;\n    float c3 = 0.5f * (y3 - y0) + 1.5f * (y1 - y2);\n    \n    return ((c3 * x + c2) * x + c1) * x + c0;\n}\n\nvoid Utils::applyWindow(float* buffer, int numSamples, WindowType windowType)\n{\n    switch (windowType)\n    {\n        case WindowType::Rectangular:\n            // No modification needed\n            break;\n            \n        case WindowType::Hann:\n            for (int i = 0; i < numSamples; ++i)\n            {\n                float window = 0.5f * (1.0f - std::cos(TWO_PI * i / (numSamples - 1)));\n                buffer[i] *= window;\n            }\n            break;\n            \n        case WindowType::Hamming:\n            for (int i = 0; i < numSamples; ++i)\n            {\n                float window = 0.54f - 0.46f * std::cos(TWO_PI * i / (numSamples - 1));\n                buffer[i] *= window;\n            }\n            break;\n            \n        case WindowType::Blackman:\n            for (int i = 0; i < numSamples; ++i)\n            {\n                float phase = TWO_PI * i / (numSamples - 1);\n                float window = 0.42f - 0.5f * std::cos(phase) + 0.08f * std::cos(2.0f * phase);\n                buffer[i] *= window;\n            }\n            break;\n            \n        case WindowType::Kaiser:\n            // Simplified Kaiser window (beta = 5.0)\n            float beta = 5.0f;\n            float alpha = (numSamples - 1) * 0.5f;\n            \n            for (int i = 0; i < numSamples; ++i)\n            {\n                float x = (i - alpha) / alpha;\n                float window = std::cosh(beta * std::sqrt(1.0f - x * x)) / std::cosh(beta);\n                buffer[i] *= window;\n            }\n            break;\n    }\n}\n\nfloat Utils::detectPitchZeroCrossing(const float* buffer, int numSamples, float sampleRate)\n{\n    if (numSamples < 2)\n        return 0.0f;\n    \n    std::vector<int> zeroCrossings;\n    \n    // Find zero crossings\n    for (int i = 1; i < numSamples; ++i)\n    {\n        if ((buffer[i-1] < 0.0f && buffer[i] >= 0.0f) ||\n            (buffer[i-1] >= 0.0f && buffer[i] < 0.0f))\n        {\n            zeroCrossings.push_back(i);\n        }\n    }\n    \n    if (zeroCrossings.size() < 2)\n        return 0.0f;\n    \n    // Calculate average period between zero crossings\n    float totalPeriod = 0.0f;\n    int periodCount = 0;\n    \n    for (size_t i = 2; i < zeroCrossings.size(); i += 2) // Use every other crossing for full periods\n    {\n        float period = static_cast<float>(zeroCrossings[i] - zeroCrossings[i-2]);\n        totalPeriod += period;\n        periodCount++;\n    }\n    \n    if (periodCount == 0)\n        return 0.0f;\n    \n    float averagePeriod = totalPeriod / periodCount;\n    return sampleRate / averagePeriod;\n}\n\nfloat Utils::calculateSpectralCentroid(const std::vector<float>& magnitude, float sampleRate)\n{\n    if (magnitude.empty())\n        return 0.0f;\n    \n    float numerator = 0.0f;\n    float denominator = 0.0f;\n    \n    for (size_t i = 1; i < magnitude.size(); ++i)\n    {\n        float frequency = static_cast<float>(i) * sampleRate / (2.0f * (magnitude.size() - 1));\n        numerator += frequency * magnitude[i];\n        denominator += magnitude[i];\n    }\n    \n    return denominator > 0.0f ? numerator / denominator : 0.0f;\n}\n\nstd::vector<int> Utils::findSpectralPeaks(const std::vector<float>& magnitude, float threshold)\n{\n    std::vector<int> peaks;\n    \n    if (magnitude.size() < 3)\n        return peaks;\n    \n    for (size_t i = 1; i < magnitude.size() - 1; ++i)\n    {\n        if (magnitude[i] > magnitude[i-1] && \n            magnitude[i] > magnitude[i+1] && \n            magnitude[i] > threshold)\n        {\n            peaks.push_back(static_cast<int>(i));\n        }\n    }\n    \n    return peaks;\n}\n\njuce::String Utils::noteNumberToNoteName(int noteNumber)\n{\n    const char* noteNames[] = {\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"};\n    \n    int octave = noteNumber / 12 - 1; // MIDI note 60 is C4\n    int note = noteNumber % 12;\n    \n    if (note < 0)\n    {\n        note += 12;\n        octave--;\n    }\n    \n    return juce::String(noteNames[note]) + juce::String(octave);\n}\n\nint Utils::noteNameToNoteNumber(const juce::String& noteName)\n{\n    // Simple implementation - could be expanded for more robust parsing\n    if (noteName.length() < 2)\n        return 60; // Default to C4\n    \n    char noteLetter = noteName[0];\n    int noteOffset = 0;\n    \n    switch (noteLetter)\n    {\n        case 'C': noteOffset = 0; break;\n        case 'D': noteOffset = 2; break;\n        case 'E': noteOffset = 4; break;\n        case 'F': noteOffset = 5; break;\n        case 'G': noteOffset = 7; break;\n        case 'A': noteOffset = 9; break;\n        case 'B': noteOffset = 11; break;\n        default: return 60;\n    }\n    \n    // Check for sharp\n    int index = 1;\n    if (noteName.length() > 2 && noteName[1] == '#')\n    {\n        noteOffset++;\n        index = 2;\n    }\n    \n    // Get octave\n    int octave = noteName.substring(index).getIntValue();\n    \n    return (octave + 1) * 12 + noteOffset;\n}\n\nfloat Utils::centsToRatio(float cents)\n{\n    return std::pow(2.0f, cents / 1200.0f);\n}\n\nfloat Utils::ratioToCents(float ratio)\n{\n    if (ratio <= 0.0f)\n        return 0.0f;\n    \n    return 1200.0f * std::log2(ratio);\n}\n\nvoid Utils::normalize(float* buffer, int numSamples, float targetLevel)\n{\n    if (numSamples <= 0)\n        return;\n    \n    // Find peak\n    float peak = 0.0f;\n    for (int i = 0; i < numSamples; ++i)\n    {\n        peak = std::max(peak, std::abs(buffer[i]));\n    }\n    \n    if (peak > 0.0f)\n    {\n        float scale = targetLevel / peak;\n        for (int i = 0; i < numSamples; ++i)\n        {\n            buffer[i] *= scale;\n        }\n    }\n}\n\nfloat Utils::calculateCorrelation(const float* buffer1, const float* buffer2, int numSamples)\n{\n    if (numSamples <= 0)\n        return 0.0f;\n    \n    float sum1 = 0.0f, sum2 = 0.0f;\n    float sum1Sq = 0.0f, sum2Sq = 0.0f;\n    float sumProduct = 0.0f;\n    \n    for (int i = 0; i < numSamples; ++i)\n    {\n        sum1 += buffer1[i];\n        sum2 += buffer2[i];\n        sum1Sq += buffer1[i] * buffer1[i];\n        sum2Sq += buffer2[i] * buffer2[i];\n        sumProduct += buffer1[i] * buffer2[i];\n    }\n    \n    float n = static_cast<float>(numSamples);\n    float numerator = n * sumProduct - sum1 * sum2;\n    float denominator = std::sqrt((n * sum1Sq - sum1 * sum1) * (n * sum2Sq - sum2 * sum2));\n    \n    return denominator > 0.0f ? numerator / denominator : 0.0f;\n}\n\nvoid Utils::fadeInOut(float* buffer, int numSamples, int fadeLength)\n{\n    if (fadeLength <= 0 || numSamples <= 0)\n        return;\n    \n    fadeLength = std::min(fadeLength, numSamples / 2);\n    \n    // Fade in\n    for (int i = 0; i < fadeLength; ++i)\n    {\n        float fade = static_cast<float>(i) / fadeLength;\n        buffer[i] *= fade;\n    }\n    \n    // Fade out\n    for (int i = numSamples - fadeLength; i < numSamples; ++i)\n    {\n        float fade = static_cast<float>(numSamples - 1 - i) / fadeLength;\n        buffer[i] *= fade;\n    }\n}\n\n// Fast trigonometric functions using lookup tables\nvoid Utils::initializeLookupTables()\n{\n    static bool initialized = false;\n    if (initialized)\n        return;\n    \n    for (int i = 0; i < LOOKUP_TABLE_SIZE; ++i)\n    {\n        float angle = TWO_PI * i / LOOKUP_TABLE_SIZE;\n        sinLookupTable[i] = std::sin(angle);\n        cosLookupTable[i] = std::cos(angle);\n    }\n    \n    initialized = true;\n}\n\nfloat Utils::lookupSin(float x)\n{\n    initializeLookupTables();\n    \n    // Normalize to [0, 2π)\n    x = std::fmod(x, TWO_PI);\n    if (x < 0.0f)\n        x += TWO_PI;\n    \n    // Convert to table index\n    float indexFloat = x * LOOKUP_TABLE_SIZE * INV_TWO_PI;\n    int index = static_cast<int>(indexFloat);\n    float fraction = indexFloat - index;\n    \n    // Linear interpolation between adjacent values\n    int nextIndex = (index + 1) % LOOKUP_TABLE_SIZE;\n    return sinLookupTable[index] + fraction * (sinLookupTable[nextIndex] - sinLookupTable[index]);\n}\n\nfloat Utils::lookupCos(float x)\n{\n    initializeLookupTables();\n    \n    // Normalize to [0, 2π)\n    x = std::fmod(x, TWO_PI);\n    if (x < 0.0f)\n        x += TWO_PI;\n    \n    // Convert to table index\n    float indexFloat = x * LOOKUP_TABLE_SIZE * INV_TWO_PI;\n    int index = static_cast<int>(indexFloat);\n    float fraction = indexFloat - index;\n    \n    // Linear interpolation between adjacent values\n    int nextIndex = (index + 1) % LOOKUP_TABLE_SIZE;\n    return cosLookupTable[index] + fraction * (cosLookupTable[nextIndex] - cosLookupTable[index]);\n}\n\nfloat Utils::fastSin(float x)\n{\n    return lookupSin(x);\n}\n\nfloat Utils::fastCos(float x)\n{\n    return lookupCos(x);\n}\n\nfloat Utils::fastAtan2(float y, float x)\n{\n    // Fast approximation of atan2\n    if (x == 0.0f)\n    {\n        return (y > 0.0f) ? HALF_PI : -HALF_PI;\n    }\n    \n    float atan = y / x;\n    float absAtan = std::abs(atan);\n    \n    // Polynomial approximation\n    float result = HALF_PI - atan / (1.0f + 0.28f * absAtan);\n    \n    if (x < 0.0f)\n    {\n        result = (y >= 0.0f) ? result + PI : result - PI;\n    }\n    \n    return result;\n}\n\nfloat Utils::fastLog2(float x)\n{\n    // Fast log2 approximation using bit manipulation\n    if (x <= 0.0f)\n        return -100.0f; // Approximation of -infinity\n    \n    union { float f; int i; } u;\n    u.f = x;\n    \n    float exponent = static_cast<float>((u.i >> 23) & 0xFF) - 127.0f;\n    u.i = (u.i & 0x007FFFFF) | 0x3F800000; // Keep mantissa, set exponent to 0\n    \n    // Polynomial approximation for mantissa\n    float mantissa = u.f;\n    float mantissaLog = -1.49278f + (2.11263f + (-0.729104f + 0.10969f * mantissa) * mantissa) * mantissa;\n    \n    return exponent + mantissaLog;\n}\n\nfloat Utils::fastPow(float base, float exponent)\n{\n    if (base <= 0.0f)\n        return 0.0f;\n    \n    return std::exp(exponent * std::log(base)); // Could be optimized further with lookup tables\n}\n","size_bytes":12852}}}